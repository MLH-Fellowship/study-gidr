{
  "name": "./pdf/Yves Hilpisch - Python for Finance  Analyze Big Financial Data-O'Reilly Media (2015).pdf",
  "heading": [
    "Editors: ",
    "Illustrator: ",
    "Using Code Examples",
    "How to Contact Us",
    "Acknowledgments",
    "What Is Python%3F",
    "Python 0.9.0",
    "Python 1.0",
    "Python 2.0",
    "Python 2.6",
    "Python 2.7",
    "Python 3.0",
    "Python 3.3",
    "Python 3.4",
    "The Python Ecosystem",
    "Python User Spectrum",
    "The Scientific Stack",
    "Python for Finance",
    "English",
    "Mathematics",
    "Python",
    "Conclusions",
    "Further Reading",
    "Python Deployment",
    "Anaconda",
    "NameDescription",
    "Python",
    "IPython",
    "Basic usage",
    "Markdown and LaTeX",
    "Magic commands",
    "Description",
    "Spyder",
    "Conclusions",
    "Further Reading",
    "Implied Volatilities",
    "Pure Python",
    "Vectorization",
    "Technical Analysis",
    "Conclusions",
    "Further Reading",
    "Basic Data Types",
    "Integers",
    "Large Integers",
    "Floats",
    "Regular Expressions",
    "Tuples",
    "Zero-Based Numbering",
    "Looping over Lists",
    "Regular NumPy Arrays",
    "dtypeDescriptionExample",
    "Using NumPy Arrays",
    "Structured Arrays",
    "Structured Arrays",
    "Basic Vectorization",
    "Universal Functions",
    "Memory Layout",
    "Conclusions",
    "Further Reading",
    "x values",
    "y values",
    "ParameterDescription",
    "CharacterColor",
    "CharacterSymbol",
    "LocDescription",
    "Other Plot Styles",
    "ParameterDescription",
    "Financial Plots",
    "ParameterDescription",
    "3D Plotting",
    "ParameterDescription",
    "Conclusions",
    "Further Reading",
    "pandas Basics",
    "AliasDescription",
    "Basic Analytics",
    "Series Class",
    "GroupBy Operations",
    "Financial Data",
    "Regression Analysis",
    "High-Frequency Data",
    "Conclusions",
    "SQL Databases",
    "I/O with pandas",
    "FormatInputOutputRemark",
    "SQL Database",
    "From SQL to pandas",
    "Data as CSV File",
    "Data as Excel File",
    "Working with Tables",
    "Fast Complex Queries",
    "Working with Arrays",
    "Conclusions",
    "Further Reading",
    "Parallel Computing",
    "Performance Comparison",
    "Easy Parallelization",
    "Dynamic Compiling",
    "Introductory Example",
    "Quick Wins",
    "Efficiency",
    "Speed-up",
    "Memory",
    "Conclusions",
    "233Approximation",
    "Regression",
    "ParameterDescription",
    "Noisy data",
    "Regression",
    "Interpolation",
    "ParameterDescription",
    "ParameterDescription",
    "Interpolation",
    "Convex Optimization",
    "Global Optimization",
    "Local Optimization",
    "Numerical Integration",
    "Symbolic Computation",
    "Basics",
    "Equations",
    "Integration",
    "Differentiation",
    "Symbolic Computations",
    "Conclusions",
    "Further Reading",
    "Random Numbers",
    "Standard normal",
    "Normal",
    "Chi square",
    "Poisson",
    "Simulation",
    "Random Variables",
    "Stochastic Processes",
    "Square-root diffusion",
    "Stochastic volatility",
    "Jump diffusion",
    "Variance Reduction",
    "Valuation",
    "European Options",
    "American Options",
    "Risk Measures",
    "Value-at-Risk",
    "Conclusions",
    "Further Reading",
    "Normality Tests",
    "Benchmark Case",
    "Normality",
    "Real-World Data",
    "Portfolio Optimization",
    "The Data",
    "The Basic Theory",
    "Language",
    "Efficient Frontier",
    "Capital Market Line",
    "Applying PCA",
    "Bayesian Regression",
    "Normalizing constant",
    "Likelihood",
    "Introductory Example",
    "Conclusions",
    "Further Reading",
    " type",
    "Using OpenPyxl",
    "Installing DataNitro",
    "AttributeDescription",
    "AttributeDescription",
    "AttributeDescription",
    "User-defined functions",
    "xlwings",
    "Conclusions",
    "Further Reading",
    "Object Orientation",
    "Updating of Values",
    "Conclusions",
    "Further Reading",
    "Web Basics",
    "ftplib",
    "httplib",
    "urllib",
    "Web Plotting",
    "Static Plots",
    "Interactive Plots",
    "Real-Time Plots",
    "Real-time FX data",
    "Data Modeling",
    "The Python Code",
    "Templating",
    "Styling",
    "Web Services",
    "The Financial Model",
    "Conclusions",
    "Further Reading",
    "A Simple Example",
    "The General Results",
    "Constant Short Rate",
    "Market Environments",
    "Conclusions",
    "Further Reading",
    "The Simulation Class",
    "A Use Case",
    "Jump Diffusion",
    "The Simulation Class",
    "A Use Case",
    "Square-Root Diffusion",
    "The Simulation Class",
    "A Use Case",
    "Conclusions",
    "Further Reading",
    "European Exercise",
    "The Valuation Class",
    "A Use Case",
    "American Exercise",
    "The Valuation Class",
    "A Use Case",
    "Conclusions",
    "Derivatives Positions",
    "The Class",
    "A Use Case",
    "Derivatives Portfolios",
    "Conclusions",
    "Further Reading",
    "The VSTOXX Data",
    "VSTOXX Index Data",
    "VSTOXX Futures Data",
    "VSTOXX Options Data",
    "Model Calibration",
    "Option Modeling",
    "Calibration Procedure",
    "Conclusions",
    "Python Syntax",
    "SymbolDescription",
    "Documentation",
    "Unit Testing",
    "FunctionDescription",
    "Python",
    "pandas",
    "IndexSymbols",
    " C ",
    " G "
  ],
  "paragraph": [
    "Brian MacDonald and Meghan Blanchette",
    "Rebecca DemarestDecember 2014:First Edition",
    "Supplemental material (in particular, IPython Notebooks and Python scripts/modules)is available for download at http://oreilly.quant-platform.com.This book is here to help you get your job done. In general, if example code is offeredwith this book, you may use it in your programs and documentation. You do not needto contact us for permission unless you're reproducing a significant portion of the code.For example, writing a program that uses several chunks of code from this book doesnot require permission. Selling or distributing a CD-ROM of examples from O'Reillybooks does require permission. Answering a question by citing this book and quotingexample code does not require permission. Incorporating a significant amount of example code from this book into your product's documentation does require permission.We appreciate, but do not require, attribution. An attribution usually includes the title,author, publisher, and ISBN. For example: %E2%80%9CPython for Finance by Yves Hilpisch (O'Reilly). Copyright 2015 Yves Hilpisch, 978-1-491-94528-5.%E2%80%9DIf you feel your use of code examples falls outside fair use or the permission given above,feel free to contact us at permissions@oreilly.com.",
    "Please address comments and questions concerning this book to the publisher:O'Reilly Media, Inc.1005 Gravenstein Highway NorthSebastopol, CA 95472800-998-9938 (in the United States or Canada)707-829-0515 (international or local)707-829-0104 (fax)We have a web page for this book, where we list errata, examples, and any additionalinformation. You can access this page at http://bit.ly/python-finance.To comment or ask technical questions about this book, send email to bookquestions@oreilly.com.For more information about our books, courses, conferences, and news, see our websiteat http://www.oreilly.com.Find us on Facebook: http://facebook.com/oreillyFollow us on Twitter: http://twitter.com/oreillymediaWatch us on YouTube: http://www.youtube.com/oreillymedia",
    "I want to thank all those who helped to make this book a reality, in particular those whohave provided honest feedback or even completely worked out examples, like BenLerner, James Powell, Michael Schwed, Thomas Wiecki or Felix Zumstein. Similarly, Iwould like to thank reviewers Hugh Brown, Jennifer Pierce, Kevin Sheppard, and GalenWilkerson. The book benefited from their valuable feedback and the many suggestions.The book has also benefited significantly as a result of feedback I received from theparticipants of the many conferences and workshops I was able to present at in 2013and 2014: PyData, For Python Quants, Big Data in Quant Finance, EuroPython, EuroScipy, PyCon DE, PyCon Ireland, Parallel Data Analysis, Budapest BI Forum and",
    "Python is a high-level, multipurpose programming language that is used in a wide rangeof domains and technical fields. On the Python website you find the following executivesummary (cf. https://www.python.org/doc/essays/blurb):Python is an interpreted, object-oriented, high-level programming language with dynamic semantics. Its high-level built in data structures, combined with dynamic typingand dynamic binding, make it very attractive for Rapid Application Development, as wellas for use as a scripting or glue language to connect existing components together.Python's simple, easy to learn syntax emphasizes readability and therefore reduces thecost of program maintenance. Python supports modules and packages, which encouragesprogram modularity and code reuse. The Python interpreter and the extensive standardlibrary are available in source or binary form without charge for all major platforms, andcan be freely distributed.This pretty well describes whyPythonhas evolved into one of the major programminglanguages as of today. Nowadays, Pythonis used by the beginner programmer as wellas by the highly skilled expert developer, at schools, in universities, at web companies,in large corporations and financial institutions, as well as in any scientific field.Among others, Python is characterized by the following features:Open sourcePython and the majority of supporting libraries and tools available are open sourceand generally come with quite flexible and open licenses.",
    " released in 1991 (first release)%E2%80%A2",
    " released in 1994%E2%80%A2",
    " released in 2000%E2%80%A2",
    " released in 2008%E2%80%A2",
    " released in 2010%E2%80%A2",
    " released in 2008%E2%80%A2",
    " released in 2010%E2%80%A2",
    " released in 2014It is remarkable, and sometimes confusing to Python newcomers, that there are twomajor versions available, still being developed and, more importantly, in parallel usesince 2008. As of this writing, this will keep on for quite a while since neither is there100%25 code compatibility between the versions, nor are all popular libraries available forPython 3.x. The majority of code available and in production is still Python 2.6/2.7,",
    "A major feature of Python as an ecosystem, compared to just being a programminglanguage, is the availability of a large number of libraries and tools. These libraries andtools generally have to be imported when needed (e.g., a plotting library) or have to bestarted as a separate system process (e.g., a Python development environment). Importing means making a library available to the current namespace and the currentPython interpreter process.Python itself already comes with a large set of libraries that enhance the basic interpreterin different directions. For example, basic mathematical calculations can be donewithout any importing, while more complex mathematical functions need to be imported through the math library:In[2]:100*2.5%2B50Out[2]: 300.0In[3]:log(1)...NameError: name 'log' is not definedIn[4]:frommathimport*In[5]:log(1)Out[5]: 0.0Although the so-called %E2%80%9Cstar import%E2%80%9D (i.e., the practice of importing everything from alibrary via from library import *) is sometimes convenient, one should generally usean alternative approach that avoids ambiguity with regard to name spaces and relationships of functions to libraries. This then takes on the form:In[6]:importmathIn[7]:math.log(1)Out[7]: 0.0While math is a standard Pythonlibrary available with any installation, there are manymore libraries that can be installed optionally and that can be used in the very samefashion as the standard libraries. Such libraries are available from different (web) sources. However, it is generally advisable to use a Pythondistribution that makes sure thatall libraries are consistent with each other (see Chapter 2 for more on this topic).",
    "Pythondoes not only appeal to professional software developers%3B it is also of use for thecasual developer as well as for domain experts and scientific developers.Professional software developers find all that they need to efficiently build large applications. Almost all programming paradigms are supported%3B there are powerful development tools available%3B and any task can, in principle, be addressed with Python. Thesetypes of users typically build their own frameworks and classes, also work on the fundamental Python and scientific stack, and strive to make the most of the ecosystem.Scientific developers or domain expertsare generally heavy users of certain libraries andframeworks, have built their own applications that they enhance and optimize over time,and tailor the ecosystem to their specific needs. These groups of users also generallyengage in longer interactive sessions, rapidly prototyping new code as well as exploringand visualizing their research and/or domain data sets.",
    "There is a certain set of libraries that is collectively labeled the scientific stack. This stackcomprises, among others, the following libraries:NumPyNumPy provides a multidimensional array object to store homogenous or heterogeneous data%3B it also provides optimized functions/methods to operate on this arrayobject.SciPySciPy is a collection of sublibraries and functions implementing important standard functionality often needed in science or finance%3B for example, you will findfunctions for cubic splines interpolation as well as for numerical integration.matplotlibThis is the most popular plotting and visualization library for Python, providingboth 2D and 3D visualization capabilities.PyTablesPyTables is a popular wrapper for the HDF5data storage library (cf. http://www.hdfgroup.org/HDF5/)%3B it is a library to implement optimized, disk-based I/Ooperations based on a hierarchical database/file format.",
    "The previous section describes some selected aspects characterizing the role of technology in finance:%E2%80%A2Costs for technology in the finance industry%E2%80%A2Technology as an enabler for new business and innovation%E2%80%A2Technology and talent as barriers to entry in the finance industry%E2%80%A2Increasing speeds, frequencies, and data volumes%E2%80%A2The rise of real-time analyticsIn this section, we want to analyze how Python can help in addressing several of thechallenges implied by these aspects. But first, on a more fundamental level, let us examine Python for finance from a language and syntax standpoint.",
    " for writing, talking about scientific and financial problems, etc.%E2%80%A2",
    " for concisely and exactly describing and modeling abstract aspects,algorithms, complex quantities, etc.%E2%80%A2",
    " for technically modeling and implementing abstract aspects, algorithms,complex quantities, etc.",
    "Python as a language-but much more so as an ecosystem-is an ideal technologicalframework for the financial industry. It is characterized by a number of benefits, like anelegant syntax, efficient development approaches, and usability for prototyping and",
    "There are two books available that cover the use of Python in finance:%E2%80%A2Fletcher, Shayne and Christopher Gardner (2009): Financial Modelling in Python.John Wiley %26 Sons, Chichester, England.%E2%80%A2Hilpisch, Yves (2015): Derivatives Analytics with Python. Wiley Finance, Chichester, England. http://derivatives-analytics-with-python.com.The quotes in this chapter are taken from the following resources:%E2%80%A2Crosman, Penny (2013): %E2%80%9CTop 8 Ways Banks Will Spend Their 2014 IT Budgets.%E2%80%9DBank Technology News.%E2%80%A2Deutsche B%C3%B6rse Group (2008): %E2%80%9CThe Global Derivatives Market-An Introduction.%E2%80%9DWhite paper.%E2%80%A2Ding, Cubillas (2010): %E2%80%9COptimizing the OTC Pricing and Valuation Infrastructure.%E2%80%9DCelent study.%E2%80%A2Lewis, Michael (2014): Flash Boys. W. W. Norton %26 Company, New York.%E2%80%A2Patterson, Scott (2010): The Quants. Crown Business, New York.",
    "This section shows how to deploy Pythonlocally (or on a server) as well as via the webbrowser.",
    "A number of operating systems come with a version of Pythonand a number of additional libraries already installed. This is true, for example, of Linux operating systems,which often rely on Python as their main language (for packaging, administration, etc.).However, in what follows we assume that Python is not installed or that we are installingan additional version of Python (in parallel to an existing one) using the Anacondadistribution.You can download Anacondafor your operating system from the website http://continuum.io/downloads. There are a couple of reasons to consider using Anacondafor Pythondeployment. Among them are:Libraries/packagesYou get more than 100 of the most important Python libraries and packages in asingle installation step%3B in particular, you get all these installed in a version-consistent manner (i.e., all libraries and packages work with each other).2Open sourceThe Anaconda distribution is free of charge in general,3 as are all libraries and packages included in the distribution.Cross platformIt is available for Windows, Mac OS, and Linux platforms.",
    "BitArrayObject types for arrays of BooleansCubesOLAPFramework for Online Analytical Processing (OLAP) applicationsDiscomapreduce implementation for distributed computingGdataImplementation of Google Data Protocolh5pyPython wrapper around HDF5 file formatHDF5File format for fast I/O operationsIPythonInteractive development environment (IDE)lxmlProcessing XML and HTML with PythonmatplotlibStandard 2D and 3D plotting libraryMPI4PyMessage Parsing Interface (MPI) implementation for parallel computationMPICH2Another MPI implementation",
    "For completeness, let us first consider using the standard Pythoninterpreter itself. Fromthe system shell/command-line interface, Python is invoked by simply typing python:%24 pythonPython 2.7.6 %7CAnaconda 1.9.2 (x86_64)%7C (default, Feb 10 2014, 17:56:29)[GCC 4.0.1 (Apple Inc. build 5493)] on darwin",
    "IPython was used in Chapter 1 to present the first examples of Python code. This sectiongives an overview of the capabilities of IPythonthrough specific examples. A completeecosystem has evolved around IPythonthat is so successful and appealing that users ofother languages make use of the basic approach and architecture it provides. For example, there is a version of IPython for the Julia language.",
    "In what follows, we describe the basic usage of the IPython Notebook. A fundamentalconcept of the Notebook is that you work with different kinds of cells. These include thefollowing types:CodeContains executable Python codeMarkdownContains text written in Markdown language and/or HTMLRaw textContains text without formatting6Heading (1-6)Headings for text structuring, e.g., section heads",
    "The following shows a few selected examples for Markdown commands:**bold** prints the text in bold*italic* prints the text in italic_italic_ also prints it in italic**_italic_** bold and italicbullet point lists:* first_bullet* second_bullet%26ndash%3B renders to a dash%3Cbr%3E inserts a line breakFigure 2-4 shows the same code both in a raw text cell (which looks the same as thepreceding text) and rendered in a Markdown cell. In this way, you can easily combinePython code and formatted, nicely rendered text in a single document.A detailed description of the Markdownlanguage used for IPython Notebook is foundat http://daringfireball.net/projects/markdown/.As mentioned before, the rendering capabilities of IPythonare not restricted to theMarkdown language. IPythonalso renders by default mathematical formulae describedon the basis of the LaTeX typesetting system, the de facto standard for scientific publishing. Consider, for example, from Chapter 1 the formula for the index level in theBlack-Scholes-Merton (1973) model, as provided in Equation 1-1. For convenience, werepeat it here as Equation 2-1.Equation 2-1. Black-Scholes-Merton (1973) index level at maturityST=S0expr%E2%88%9212%CF%832T%2B%CF%83Tz",
    "One of IPython's strengths lies in its magic commands. They are %E2%80%9Cmagic%E2%80%9D in the sensethat they add some really helpful and powerful functions to the standard Python shellfunctionality. Basic information and help about these functions can be accessed via:In [1]: %25magicIPython's 'magic' functions===========================The magic function system provides a series of functions which allow you tocontrol the behavior of IPython itself, plus a lot of system-typefeatures. There are two kinds of magics, line-oriented and cell-oriented....A list of all available magic commands can be generated in an IPython session as follows:In[2]:%25lsmagicIn interactive computing, magic commands can, for example, be used for simple profiling tasks. For such a use case, you might use %25time or %25prun:",
    "%3FIntroduction and overview of IPython features%25quickrefQuick referencehelpPython's own help systemobject%3FDetails about the %E2%80%9Cobject%E2%80%9D%3B use object%3F%3F for extra detailsAnother feature of IPython is that it is highly configurable. Information about the configuration capabilities is also found in the documentation.A magic command that also helps with customizing IPython is %25bookmark. This allowsthe bookmarking of arbitrary directories by the use of your custom names such thatyou can later-no matter where the IPython kernel is invoked from and no matter whatthe current directory is-navigate to any of your bookmarked directories immediately",
    "While IPython satisfies all of most users' requirements for interactive analytics andprototyping, larger projects generally demand %E2%80%9Csomething more.%E2%80%9D In particular, IPythonitself has no editor directly built into the application.7For all those looking for a moretraditional development environment, Spyder might therefore be a good choice.Similar to IPython, Spyder has been designed to support rapid, interactive developmentwith Python. However, it also has, for example, a full-fledged editor, more powerful",
    "If you are a beginner or casual Pythondeveloper or an expert coming from a differentprogramming background, getting started with Pythonis generally pretty easy in thatonly a couple of simple steps are required. To begin, you should install an appropriatePython distribution, like Anaconda, to have a consistent Python environment availableand also to simplify the regular updating procedures.With a distribution like Anacondayou have available the most important tools to interactively practice data and financial analytics, like with IPython, or to develop largerapplications in a more traditional implement-test-debug fashion, like with Spyder. Ofcourse, you can add to the mix your favorite editor, which probably already has Pythonsyntax highlighting included. If you additionally are looking for syntax and code check",
    "The following web resources are helpful with regard to the topics covered in this chapter:%E2%80%A2http://docs.continuum.io/anaconda/ for the Anaconda documentation%E2%80%A2http://conda.pydata.org/docs/ for the conda documentation%E2%80%A2http://ipython.org/ipython-doc/stable/ for the IPython documentation%E2%80%A2http://daringfireball.net/projects/markdown/ for the Markdownlanguage used byIPython Notebook%E2%80%A2http://code.google.com/p/spyderlib for information about SpyderA good introduction to Pythondeployment and the use of IPythonas a developmentenvironment is provided in:%E2%80%A2Wes McKinney (2012): Python for Data Analysis. O'Reilly, Sebastopol, CA.",
    "Given an option pricing formula like the seminal one of Black-Scholes-Merton (1973),implied volatilities are those volatility values that, ceteris paribus, when put into theformula, give observed market quotes for different option strikes and maturities. In thiscase, the volatility is not an input parameter for the model/formula, but the result of a(numerical) optimization procedure given that formula.The example we consider in the following discussion is about a new generation of options, namely volatility options on the VSTOXX volatility index. Eurex, the derivativesexchange that provides these options on the VSTOXX and respective futures contracts,established a comprehensive Python-based tutorial called %E2%80%9CVSTOXX Advanced Services%E2%80%9D in June 2013 about the index and its derivatives contracts.1However, before proceeding with the VSTOXX options themselves, let us first reproduce in Equation 3-1 the famous Black-Scholes-Merton formula for the pricing of European call options on an underlying without dividends.Equation 3-1. Black-Scholes-Merton (1973) option pricing formula C St,K,t,T,r,%CF%83=St%C2%B7%ED%90%80d1%E2%88%92e%E2%88%92rT%E2%88%92t%C2%B7K%C2%B7%ED%90%80d2%ED%90%80d=12%CF%80%E2%88%92%E2%88%9Ede%E2%88%9212x2dxd1=logStK%2Br%2B%CF%8322T%E2%88%92t%CF%83T%E2%88%92td2=logStK%2Br%E2%88%92%CF%8322T%E2%88%92t%CF%83T%E2%88%92tThe different parameters have the following meaning:",
    "Example 3-2 translates the parametrization and the Monte Carlo recipe into purePython. The code simulates 250,000 paths over 50 time steps.Example 3-2. Monte Carlo valuation of European call option with pure Python## Monte Carlo valuation of European call options with pure Python# mcs_pure_python.py#fromtimeimporttimefrommathimportexp,sqrt,logfromrandomimportgauss,seedseed(20000)t0=time()",
    "Using vectorization with NumPy generally results in code that is morecompact,easiertoread(andmaintain),andfastertoexecute.Alltheseaspects are in general important for financial applications.",
    "Technical analysis based on historical price information is a typical task finance professionals and interested amateurs engage in. On Wikipediayou find the followingdefinition:",
    "Without going into too much detail, this chapter illustrates the use of Python by themeans of concrete and typical financial examples:Calculation of implied volatilitiesUsing real-world data, in the form of a cross section of option data for a given day,we calculate numerically the implied volatilities of European call options on the",
    "The major references used in this chapter are:%E2%80%A2Black, Fischer and Myron Scholes (1973): %E2%80%9CThe Pricing of Options and CorporateLiabilities.%E2%80%9D Journal of Political Economy, Vol. 81, No. 3, pp. 638-659.%E2%80%A2Hilpisch, Yves (2015): Derivatives Analytics with Python. Wiley Finance, Chichester, England. http://www.derivatives-analytics-with-python.com.%E2%80%A2Hilpisch, Yves (2013): %E2%80%9CEfficient Data and Financial Analytics with Python.%E2%80%9D Software Developer's Journal, No. 13, pp. 56-65. http://hilpisch.com/YH_Efficient_Analytics_Article.pdf.%E2%80%A2Merton, Robert (1973): %E2%80%9CTheory of Rational Option Pricing.%E2%80%9D Bell Journal of Economics and Management Science, Vol. 4, pp. 141-183.",
    "Python is a dynamically typed language, which means that the Pythoninterpreter infersthe type of an object at runtime. In comparison, compiled languages like  C are generallystatically typed. In these cases, the type of an object has to be attached to the object beforecompile time.1",
    "One of the most fundamental data types is the integer, or int:In[1]:a=10type(a)Out[1]: intThe built-in function typeprovides type information for all objects with standard andbuilt-in types as well as for newly created classes and objects. In the latter case, theinformation provided depends on the description the programmer has stored with theclass. There is a saying that %E2%80%9Ceverything in Python is an object.%E2%80%9D This means, for example,that even simple objects like the intobject we just defined have built-in methods. Forexample, you can get the number of bits needed to represent the int object in-memoryby calling the method bit_length:In[2]:a.bit_length()Out[2]: 4You will see that the number of bits needed increases the higher the integer value is thatwe assign to the object:In[3]:a=100000a.bit_length()Out[3]: 17In general, there are so many different methods that it is hard to memorize all methodsof all classes and objects. Advanced Pythonenvironments, like IPython, provide tabcompletion capabilities that show all methods attached to an object. You simply typethe object name followed by a dot (e.g., a.) and then press the Tab key, e.g., a.tab. Thisthen provides a collection of methods you can call on the object. Alternatively, the",
    "Pythonintegerscanbearbitrarilylarge.Theinterpretersimplyusesas many bits/bytes as needed to represent the numbers.It is important to note that mathematical operations on int objects return int objects.This can sometimes lead to confusion and/or hard-to-detect errors in mathematicalroutines. The following expression yields the expected result:In[6]:1%2B4Out[6]: 5However, the next case may return a somewhat surprising result:In[7]:1/4Out[7]: 0In[8]:type(1/4)Out[8]: int",
    "For the last expression to return the generally desired result of 0.25, we must operate onfloatobjects, which brings us naturally to the next basic data type. Adding a dot to aninteger value, like in 1. or 1.0, causes Python to interpret the object as a float. Expressions involving a float also return a float object in general:2",
    "Whenparsingstringobjects,considerusingregularexpressions,whichcanbringbothconvenienceandperformancetosuchoperations.The resulting stringobjects can then be parsed to generate Python datetime objects(cf. Appendix Cfor an overview of handling date and time data with Python). To parsethe stringobjects containing the date-time information, we need to provide information of how to parse-again as a string object:In[34]:fromdatetimeimportdatetimepydt=datetime.strptime(result[0].replace(%22'%22,%22%22),'%25m/%25d/%25Y %25H:%25M:%25S')pydtOut[34]: datetime.datetime(2014, 1, 18, 13, 0)In[35]:printpydtOut[35]: 2014-01-18 13:00:00In[36]:printtype(pydt)Out[36]: %3Ctype 'datetime.datetime'%3ELater chapters provide more information on date-time data, the handling of such data,and datetimeobjects and their methods. This is just meant to be a teaser for this important topic in finance.",
    "A tupleis an advanced data structure, yet it's still quite simple and limited in its applications. It is defined by providing objects in parentheses:In[37]:t=(1,2.5,'data')type(t)Out[37]: tupleYou can even drop the parentheses and provide multiple objects separated by commas:In[38]:t=1,2.5,'data'type(t)Out[38]: tupleLike almost all data structures in Python the tuplehas a built-in index, with the helpof which you can retrieve single or multiple elements of the tuple. It is important toremember that Python uses zero-based numbering, such that the third element of a tupleis at index position 2:In[39]:t[2]Out[39]: 'data'In[40]:type(t[2])Out[40]: str",
    "IncontrasttosomeotherprogramminglanguageslikeMatlab,Pythonuseszero-basednumberingschemes.Forexample,thefirstelement of a tuple object has index value 0.There are only two special methods that this object type provides: count and index. Thefirst counts the number of occurrences of a certain object and the second gives the indexvalue of the first appearance of it:",
    "In Python you can loop over arbitrary list objects, no matter whatthecontentoftheobjectis.Thisoftenavoidstheintroductionofacounter.Python also provides the typical (conditional) control elements if, elif, and else. Theiruse is comparable in other languages:In[56]:foriinrange(1,10):ifi%252==0:# %25 is for moduloprint%22%25d is even%22%25ielifi%253==0:print%22%25d is multiple of 3%22%25ielse:print%22%25d is odd%22%25iOut[56]: 1 is odd         2 is even         3 is multiple of 3         4 is even         5 is odd         6 is even         7 is odd         8 is even         9 is multiple of 3",
    "Obviously, composing array structures with list objects works, somewhat. But it is notreally convenient, and the listclass has not been built with this specific goal in mind.It has rather been built with a much broader and more general scope. From this pointof view, some kind of specialized class could therefore be really beneficial to handlearray-type structures.Such a specialized class is numpy.ndarray, which has been built with the specific goalof handling n-dimensional arrays both conveniently and efficiently-i.e., in a highlyperforming manner. The basic handling of instances of this class is again best illustratedby examples:In[94]:importnumpyasnpIn[95]:a=np.array([0,0.5,1.0,1.5,2.0])type(a)Out[95]: numpy.ndarrayIn[96]:a[:2]# indexing as with list objects in 1 dimensionOut[96]: array([ 0. ,  0.5])A major feature of the numpy.ndarray class is the multitude of built-in methods. Forinstance:",
    "tBit fieldt4 (4 bits)bBooleanb (true or false)iIntegeri8 (64 bit)uUnsigned integeru8 (64 bit)fFloating pointf8 (64 bit)cComplex floating pointc16 (128 bit)OObject0 (pointer to object)S, aStringS24 (24 characters)UUnicodeU24 (24 Unicode characters)VOtherV12 (12-byte data block)NumPyprovides a generalization of regular arrays that loosens at least the dtype restriction, but let us stick with regular arrays for a moment and see what the specializationbrings in terms of performance.As a simple exercise, suppose we want to generate a matrix/array of shape 5,000 %C3%97 5,000elements, populated with (pseudo)random, standard normally distributed numbers.We then want to calculate the sum of all elements. First, the pure Pythonapproach,where we make heavy use of list comprehensions and functional programming methods as well as lambda functions:In[111]:importrandomI=5000In[112]:%25timemat=[[random.gauss(0,1)forjinrange(I)]foriinrange(I)]# a nested list comprehensionOut[112]: CPU times: user 36.5 s, sys: 408 ms, total: 36.9 s          Wall time: 36.4 sIn[113]:%25timereduce(lambdax,y:x%2By,      %5C[reduce(lambdax,y:x%2By,row) %5Cforrowinmat])Out[113]: CPU times: user 4.3 s, sys: 52 ms, total: 4.35 s          Wall time: 4.07 s          678.5908519876674Let us now turn to NumPy and see how the same problem is solved there. For convenience,the NumPy sublibrary random offers a multitude of functions to initialize a numpy.ndarrayobject and populate it at the same time with (pseudo)random numbers:",
    "TheuseofNumPyforarray-basedoperationsandalgorithmsgenerallyresults in compact, easily readable code and significant performanceimprovements over pure Python code.",
    "The specialization of the numpy.ndarrayclass obviously brings a number of really valuable benefits with it. However, a too-narrow specialization might turn out to be toolarge a burden to carry for the majority of array-based algorithms and applications.Therefore, NumPyprovides structured arrays that allow us to have different NumPy datatypes per column, at least. What does %E2%80%9Cper column%E2%80%9D mean%3F Consider the following initialization of a structured array object:In[116]:dt=np.dtype([('Name','S10'),('Age','i4'),('Height','f'),('Children/Pets','i4',2)])s=np.array([('Smith',45,1.83,(0,1)),('Jones',53,1.72,(2,2))],dtype=dt)sOut[116]: array([('Smith', 45, 1.8300000429153442, [0, 1]),                 ('Jones', 53, 1.7200000286102295, [2, 2])],                dtype=[('Name', 'S10'), ('Age', '%3Ci4'), ('Height', '%3Cf4'), ('Chi          ldren/Pets', '%3Ci4', (2,))])In a sense, this construction comes quite close to the operation for initializing tables ina SQL database. We have column names and column data types, with maybe some",
    "NumPyprovides,inadditiontoregulararrays,structuredarraysthatallow the description and handling of rather complex array-orienteddata structures with a variety of different data types and even structures per (named) column. They bring SQL table-like data structurestoPython,withallthebenefitsofregularnumpy.ndarrayobjects(syntax, methods, performance).",
    "As we learned in the previous section, simple mathematical operations can be implemented on numpy.ndarray objects directly. For example, we can add two NumPy arrayselement-wise as follows:",
    "Becarefulwhenusingthefromlibraryimport*approachtoimporting.SuchanapproachcancausetheNumPyreferencetotheufuncnumpy.sintobereplacedbythereferencetothemathfunctionmath.sin.Youshould,asarule,importbothlibrariesbynametoavoidconfusion:importnumpyasnp%3Bimportmath.Thenyoucanuse math.sin alongside np.sin.",
    "When we first initialized numpy.ndarrayobjects by using numpy.zero, we provided anoptional argument for the memory layout. This argument specifies, roughly speaking,which elements of an array get stored in memory next to each other. When workingwith small arrays, this has hardly any measurable impact on the performance of arrayoperations. However, when arrays get large the story is somewhat different, dependingon the operations to be implemented on the arrays.To illustrate this important point for memory-wise handling of arrays in science andfinance, consider the following construction of multidimensional numpy.ndarrayobjects:In[133]:x=np.random.standard_normal((5,10000000))y=2*x%2B3# linear equation y = a * x %2B b C =np.array((x,y),order='C')F=np.array((x,y),order='F')x=0.0%3By=0.0# memory cleanupIn[134]: C [:2].round(2)Out[134]: array([[[-0.51, -1.14, -1.07, ...,  0.2 , -0.18,  0.1 ],                  [-1.22,  0.68,  1.83, ...,  1.23, -0.27, -0.16],                  [ 0.45,  0.15,  0.01, ..., -0.75,  0.91, -1.12],                  [-0.16,  1.4 , -0.79, ..., -0.33,  0.54,  1.81],                  [ 1.07, -1.07, -0.37, ..., -0.76,  0.71,  0.34]],                 [[ 1.98,  0.72,  0.86, ...,  3.4 ,  2.64,  3.21],                  [ 0.55,  4.37,  6.66, ...,  5.47,  2.47,  2.68],                  [ 3.9 ,  3.29,  3.03, ...,  1.5 ,  4.82,  0.76],                  [ 2.67,  5.8 ,  1.42, ...,  2.34,  4.09,  6.63],                  [ 5.14,  0.87,  2.27, ...,  1.48,  4.43,  3.67]]])",
    "Python provides, in combination with NumPy, a rich set of flexible data structures. Froma finance point of view, the following can be considered the most important ones:",
    "This chapter focuses on those issues that might be of particular importance for financealgorithms and applications. However, it can only represent a starting point for theexploration of data structures and data modeling in Python. There are a number ofvaluable resources available to go deeper from here.Here are some Internet resources to consult:%E2%80%A2The Python documentation is always a good starting point: http://www.python.org/doc/.%E2%80%A2For details on NumPy arrays as well as related methods and functions, see http://docs.scipy.org/doc/.%E2%80%A2The SciPy lecture notes are also a good source to get started: http://scipy-lectures.github.io/.Good references in book form are:%E2%80%A2Goodrich, Michael et al. (2013): Data Structures and Algorithms in Python.JohnWiley %26 Sons, Hoboken, NJ.%E2%80%A2Langtangen, Hans Petter (2009): A Primer on Scientific Programming with Python.Springer Verlag, Berlin, Heidelberg.",
    ": a list or an array containing the x coordinates (values of the abscissa)%E2%80%A2",
    ": a list or an array containing the y coordinates (values of the ordinate)The number of x and yvalues provided must match, of course. Consider the followingtwo lines of code, whose output is presented in Figure 5-1:In[3]:x=range(len(y))plt.plot(x,y)Figure 5-1. Plot given x and y valuesplotnotices when you pass an ndarrayobject. In this case, there is no need to providethe %E2%80%9Cextra%E2%80%9D information of the x values. If you only provide the y values, plot takes theindex values as the respective x values. Therefore, the following single line of codegenerates exactly the same output (cf. Figure 5-2):In[4]:plt.plot(y)",
    "EmptyReturns current axis limitsoffTurns axis lines and labels offequalLeads to equal scalingscaledEqual scaling via dimension changestightMakes all data visible (tightens limits)imageMakes all data visible (with data limits)[xmin,xmax,ymin,ymax]Sets limits to given (list of) valuesIn addition, you can directly set the minimum and maximum values of each axis byusing plt.xlim and plt.ylim. The following code provides an example whose outputis shown in Figure 5-5:In[7]:plt.plot(y.cumsum())plt.grid(True)plt.xlim(-1,20)plt.ylim(np.min(y.cumsum())-1,np.max(y.cumsum())%2B1)",
    "bBluegGreenrRedcCyanmMagentayYellowkBlackwWhiteIn terms of line and/or point styles, plt.plot supports the characters listed in Table 5-3.Table 5-3. Standard style characters",
    "-Solid line style--Dashed line style-.Dash-dot line style:Dotted line style.Point marker,Pixel markeroCircle markervTriangle_down marker%5ETriangle_up marker%3CTriangle_left marker%3ETriangle_right marker1Tri_down marker2Tri_up marker3Tri_left marker4Tri_right markersSquare markerpPentagon marker*Star markerhHexagon1 markerHHexagon2 marker%2BPlus marker",
    "EmptyAutomatic0Best possible1Upper right2Upper left3Lower left4Lower right5Right",
    "When it comes to two-dimensional plotting, line and point plots are probably the mostimportant ones in finance%3B this is because many data sets embody time series data, whichgenerally is visualized by such plots. Chapter 6addresses financial times series data indetail. However, for the moment we want to stick with the two-dimensional data setand illustrate some alternative, and for financial applications useful, visualizationapproaches.The first is the scatter plot, where the values of one data set serve as the x values for theother data set. Figure 5-13 shows such a plot. Such a plot type is used, for example, whenyou want to plot the returns of one financial time series against those of another one.For this example we will use a new two-dimensional data set with some more data:In[16]:y=np.random.standard_normal((1000,2))In[17]:plt.figure(figsize=(7,5))plt.plot(y[:,0],y[:,1],'ro')plt.grid(True)plt.xlabel('1st')plt.ylabel('2nd')plt.title('Scatter Plot')",
    "xlist object(s), ndarray objectbinsNumber of binsrangeLower and upper range of binsnormedNorming such that integral value is 1weightsWeights for every value in xcumulativeEvery bin contains the counts of the lower binshisttypeOptions (strings): bar, barstacked, step, stepfilledalignOptions (strings): left, mid, rightorientationOptions (strings): horizontal, verticalrwidthRelative width of the barslogLog scalecolorColor per data set (array-like)labelString or sequence of strings for labelsstackedStacks multiple data sets",
    "matplotlib also provides a small selection of special finance plots. These, like thecandlestick plot, are mainly used to visualize historical stock price data or similar financial time series data. Those plotting capabilities are found in the matplotlib.finance sublibrary:In[25]:importmatplotlib.financeasmpfAs a convenience function, this sublibrary allows for easy retrieval of historical stockprice data from the Yahoo! Finance website (cf. http://finance.yahoo.com). All you needare start and end dates and the respective ticker symbol. The following retrieves datafor the German DAX index whose ticker symbol is %5EGDAXI:In[26]:start=(2014,5,1)end=(2014,6,30)quotes=mpf.quotes_historical_yahoo('%5EGDAXI',start,end)",
    "axAn Axes instance to plot toquotesFinancial data to plot (sequence of time, open, close, high, low sequences)widthFraction of a day for the rectangle widthcolorupThe color of the rectangle where close %3E= opencolordownThe color of the rectangle where close %3C openalphaThe rectangle alpha levelA rather similar plot type is provided by the plot_day_summary function, which is usedin the same fashion as the candlestick function and with similar parameters. Here,opening and closing values are not illustrated by a colored rectangle but rather by twosmall horizontal lines, as Figure 5-21 shows:In[29]:fig,ax=plt.subplots(figsize=(8,5))mpf.plot_day_summary(ax,quotes,colorup='b',colordown='r')plt.grid(True)ax.xaxis_date()plt.title('DAX Index')",
    "There are not too many fields in finance that really benefit from visualization in threedimensions. However, one application area is volatility surfaces showing implied volatilities simultaneously for a number of times-of-maturity and strikes. In what follows,we artificially generate a plot that resembles a volatility surface. To this end, we consider:%E2%80%A2Strike values between 50 and 150%E2%80%A2Times-to-maturity between 0.5 and 2.5 yearsThis provides our two-dimensional coordinate system. We can use NumPy's meshgridfunction to generate such a system out of two one-dimensional ndarray objects:In[32]:strike=np.linspace(50,150,24)ttm=np.linspace(0.5,2.5,24)strike,ttm=np.meshgrid(strike,ttm)This transforms both 1D arrays into 2D arrays, repeating the original axis values asoften as needed:In[33]:strike[:2]Out[33]: array([[  50.        ,   54.34782609,   58.69565217,   63.04347826,                   67.39130435,   71.73913043,   76.08695652,   80.43478261,                   84.7826087 ,   89.13043478,   93.47826087,   97.82608696,                  102.17391304,  106.52173913,  110.86956522,  115.2173913 ,                  119.56521739,  123.91304348,  128.26086957,  132.60869565,",
    "X, Y, ZData values as 2D arraysrstrideArray row stride (step size)cstrideArray column stride (step size)colorColor of the surface patchescmapA colormap for the surface patchesfacecolorsFace colors for the individual patchesnormAn instance of Normalize to map values to colorsvminMinimum value to mapvmaxMaximum value to mapshadeWhether to shade the face colorsAs with two-dimensional plots, the line style can be replaced by single points or, as inwhat follows, single triangles. Figure 5-24plots the same data as a 3D scatter plot, butnow also with a different viewing angle, using the view_init function to set it:In[36]:fig=plt.figure(figsize=(8,5))ax=fig.add_subplot(111,projection='3d')ax.view_init(30,60)ax.scatter(strike,ttm,iv,zdir='z',s=25,c='b',marker='%5E')ax.set_xlabel('strike')ax.set_ylabel('time-to-maturity')ax.set_zlabel('implied volatility')",
    "matplotlib can be considered both the benchmark and the workhorse when it comesto data visualization in Python. It is tightly integrated with NumPy and the basic functionality is easily and conveniently accessed. However, on the other hand, matplotlibis a rather mighty library with a somewhat complex API. This makes it impossible togive a broader overview of all the capabilities of matplotlib in this chapter.This chapter introduces the basic functions of matplotlib for 2D and 3D plotting usefulin most financial contexts. Other chapters provide further examples of how to use thisfundamental library for visualization.",
    "The major resources for matplotlib can be found on the Web:%E2%80%A2The home page of matplotlibis, of course, the best starting point: http://matplotlib.org.%E2%80%A2There's a gallery with many useful examples: http://matplotlib.org/gallery.html.%E2%80%A2A tutorial for 2D plotting is found here: http://matplotlib.org/users/pyplot_tutorial.html.%E2%80%A2Another one for 3D plotting is here: http://matplotlib.org/mpl_toolkits/mplot3d/tutorial.html.",
    "In a sense, pandasis built %E2%80%9Con top%E2%80%9D of NumPy. So, for example, NumPy universal functionswill generally work on pandasobjects as well. We therefore import both to begin with:In[1]:importnumpyasnpimportpandasaspd",
    "BBusiness day frequency C Custom business day frequency (experimental)DCalendar day frequencyWWeekly frequencyMMonth end frequencyBMBusiness month end frequencyMSMonth start frequencyBMSBusiness month start frequencyQQuarter end frequencyBQBusiness quarter end frequencyQSQuarter start frequencyBQSBusiness quarter start frequencyAYear end frequencyBABusiness year end frequencyASYear start frequencyBASBusiness year start frequencyHHourly frequencyTMinutely frequencySSecondly frequencyLMilliseondsUMicrosecondsIn this subsection, we start with a NumPyndarray object and end with an enriched versionin the form of a pandasDataFrameobject. But does this procedure work the other wayaround as well%3F Yes, it does:In[26]:np.array(df).round(6)Out[26]: array([[-0.737304,  1.065173,  0.073406,  1.301174],                [-0.788818, -0.985819,  0.403796, -1.753784],                [-0.155881, -1.752672,  1.037444, -0.400793],                [-0.777546,  1.730278,  0.417114,  0.184079],                [-1.76366 , -0.375469,  0.098678, -1.553824],                [-1.134258,  1.401821,  1.227124,  0.979389],                [ 0.458838, -0.143187,  1.565701, -2.085863],",
    "Like NumPy arrays, the pandasDataFrameclass has built in a multitude of conveniencemethods. For example, you can easily get the column-wise sums, means, and cumulativesums as follows:In[27]:df.sum()Out[27]: No1   -3.961370         No2    0.445156         No3    5.131414         No4   -2.948346         dtype: float64In[28]:df.mean()Out[28]: No1   -0.440152         No2    0.049462         No3    0.570157         No4   -0.327594         dtype: float64In[29]:df.cumsum()Out[29]:                  No1       No2       No3       No4         2015-01-31 -0.737304  1.065173  0.073406  1.301174         2015-02-28 -1.526122  0.079354  0.477201 -0.452609         2015-03-31 -1.682003 -1.673318  1.514645 -0.853403         2015-04-30 -2.459549  0.056960  1.931759 -0.669323         2015-05-31 -4.223209 -0.318508  2.030438 -2.223147         2015-06-30 -5.357467  1.083313  3.257562 -1.243758         2015-07-31 -4.898629  0.940126  4.823263 -3.329621         2015-08-31 -5.001687  0.573956  4.345227 -3.362430         2015-09-30 -3.961370  0.445156  5.131414 -2.948346There is also a shortcut to a number of often-used statistics for numerical data sets, thedescribe method:In[30]:df.describe()Out[30]:             No1       No2       No3       No4         count  9.000000  9.000000  9.000000  9.000000         mean  -0.440152  0.049462  0.570157 -0.327594         std    0.847907  1.141676  0.642904  1.219345",
    "So far, we have worked mainly with the pandasDataFrame class:In[34]:type(df)Out[34]: pandas.core.frame.DataFrameBut there is also a dedicated Series class. We get a Series object, for example, whenselecting a single column from our DataFrame object:In[35]:df['No1']Out[35]: 2015-01-31   -0.737304         2015-02-28   -0.788818         2015-03-31   -0.155881         2015-04-30   -0.777546         2015-05-31   -1.763660         2015-06-30   -1.134258         2015-07-31    0.458838         2015-08-31   -0.103058         2015-09-30    1.040318         Freq: M, Name: No1, dtype: float64In[36]:type(df['No1'])Out[36]: pandas.core.series.SeriesThe main DataFrame methods are available for Series objects as well, and we can, forinstance, plot the results as before (cf. Figure 6-2):In[37]:importmatplotlib.pyplotaspltdf['No1'].cumsum().plot(style='r',lw=2.)plt.xlabel('date')plt.ylabel('value')",
    "pandas has powerful and flexible grouping capabilities. They work similarly to groupingin SQL as well as pivot tables in Microsoft Excel. To have something to group by, we adda column indicating the quarter the respective data of the index belongs to:In[38]:df['Quarter']=['Q1','Q1','Q1','Q2','Q2','Q2','Q3','Q3','Q3']dfOut[38]:                  No1       No2       No3       No4 Quarter         2015-01-31 -0.737304  1.065173  0.073406  1.301174      Q1         2015-02-28 -0.788818 -0.985819  0.403796 -1.753784      Q1         2015-03-31 -0.155881 -1.752672  1.037444 -0.400793      Q1         2015-04-30 -0.777546  1.730278  0.417114  0.184079      Q2         2015-05-31 -1.763660 -0.375469  0.098678 -1.553824      Q2         2015-06-30 -1.134258  1.401821  1.227124  0.979389      Q2         2015-07-31  0.458838 -0.143187  1.565701 -2.085863      Q3         2015-08-31 -0.103058 -0.366170 -0.478036 -0.032810      Q3         2015-09-30  1.040318 -0.128799  0.786187  0.414084      Q3Now, we can group by the %E2%80%9CQuarter%E2%80%9D column and can output statistics for the singlegroups:In[39]:groups=df.groupby('Quarter')For example, we can easily get the mean, max, and size of every group bucket as follows:In[40]:groups.mean()Out[40]:               No1       No2       No3       No4         Quarter         Q1      -0.560668 -0.557773  0.504882 -0.284468         Q2      -1.225155  0.918877  0.580972 -0.130118         Q3       0.465366 -0.212719  0.624617 -0.568196In[41]:groups.max()",
    "The Web today provides a wealth of financial information for free. Web giants such asGoogle or Yahoo! have comprehensive financial data offerings. Although the quality of",
    "The previous section introduces the leverage effect as a stylized fact of equity marketreturns. So far, the support that we provided is based on the inspection of financial dataplots only. Using pandas, we can also base such analysis on a more formal, statisticalground. The simplest approach is to use (linear) ordinary least-squares regression(OLS).In what follows, the analysis uses two different data sets available on the Web:EURO STOXX 50Historical daily closing values of the EURO STOXX 50 index, composed of European blue-chip stocksVSTOXXHistorical daily closing data for the VSTOXX volatility index, calculated on thebasis of volatilities implied by options on the EURO STOXX 50 indexIt is noteworthy that we now (indirectly) use implied volatilities, which relate to expectations with regard to the future volatility development, while the previous DAXanalysis used historical volatility measures. For details, see the %E2%80%9CVSTOXX AdvancedServices%E2%80%9D tutorial pages provided by Eurex.We begin with a few imports:In[62]:importpandasaspdfromurllibimporturlretrieve",
    "By now, you should have a feeling for the strengths of pandas when it comes to financialtime series data. One aspect in this regard has become prevalent in the financial analyticssphere and represents quite a high burden for some market players: high-frequencydata. This brief section illustrates how to cope with tick data instead of daily financialdata. To begin with, a couple of imports:In[86]:importnumpyasnpimportpandasaspdimportdatetimeasdtfromurllibimporturlretrieve%25matplotlibinlineThe Norwegian online broker Netfondsprovides tick data for a multitude of stocks, inparticular for American names. The web-based API has basically the following format:In[87]:url1='http://hopey.netfonds.no/posdump.php%3F'url2='date=%25s%25s%25s%26paper=AAPL.O%26csv_format=csv'url=url1%2Burl2We want to download, combine, and analyze a week's worth of tick data for the AppleInc. stock, a quite actively traded name. Let us start with the dates of interest:4",
    "Financial time series data is one of the most common and important forms of data infinance. The library pandas is generally the tool of choice when it comes to workingwith such data sets. Modeled after the data.frame class of R, the pandasDataFrameclassprovides a wealth of attributes and methods to attack almost any kind of (financial)analytics problem you might face. Convenience is another benefit of using pandas: evenif you might be able to generate the same result by using NumPy and/or matplotlibonly,pandas generally has some neat shortcuts based on a powerful and flexible API.In addition, pandasmakes it really easy to retrieve data from a variety of web sources,like Yahoo! Finance or Google. Compared to %E2%80%9Cpure%E2%80%9D NumPy or matplotlib, it automatesthe management of financial time series data in many respects and also provides higherflexibility when it comes to combining data sets and enlarging existing ones.",
    "Python can work with any kind of SQL database and in general also with any kind ofNoSQLdatabase. One database that is delivered with Pythonby default is SQLite3. Withit, the basic Python approach to SQL databases can be easily illustrated:2In[40]:importsqlite3assq3SQL queries are formulated as string objects. The syntax, data types, etc. of coursedepend on the database in use:In[41]:query='CREATE TABLE numbs (Date date, No1 real, No2 real)'Open a database connection. In this case, we generate a new database file on disk:In[42]:con=sq3.connect(path%2B'numbs.db')Then execute the query statement to create the table by using the method execute:In[43]:con.execute(query)Out[43]: %3Csqlite3.Cursor at 0xb8a4490%3ETo make the query effective, call the method commit:In[44]:con.commit()",
    "One of the major strengths of the pandaslibrary is that it can read and write differentdata formats natively, including among others:%E2%80%A2CSV (comma-separated value)%E2%80%A2SQL (Structured Query Language)%E2%80%A2XLS/XSLX (Microsoft Excel files)%E2%80%A2JSON (JavaScriptObject Notation)%E2%80%A2HTML (HyperText Markup Language)Table 7-1 lists all the supported formats and the corresponding import and exportfunctions/methods of pandas. The parameters that the import functions take are listedand described in Table 6-6 (depending on the functions, some other conventions mightapply).Table 7-1. Parameters of DataFrame function",
    "CSVread_csvto_csvText fileXLS/XLSXread_excelto_excelSpreadsheetHDFread_hdfto_hdfHDF5 databaseSQLread_sqlto_sqlSQL tableJSONread_jsonto_jsonJavaScript Object NotationMSGPACKread_msgpackto_msgpackPortable binary formatHTMLread_htmlto_htmlHTML codeGBQread_gbqto_gbqGoogle Big Query format",
    "All that follows with regard to SQLite3 should be known by now:In[68]:importsqlite3assq3In[69]:query='CREATE TABLE numbers (No1 real, No2 real,%5C                 No3 real, No4 real, No5 real)'In[70]:con=sq3.Connection(filename%2B'.db')In[71]:con.execute(query)Out[71]: %3Csqlite3.Cursor at 0x9d59c00%3EThis time, executemany can be applied since we write from a single ndarray object:In[72]:%25%25timecon.executemany('INSERT INTO numbers VALUES (%3F, %3F, %3F, %3F, %3F)',data)con.commit()Out[72]: CPU times: user 13.9 s, sys: 229 ms, total: 14.2 s         Wall time: 14.9 sIn[73]:ll%24path*Out[73]: -rw-r--r-- 1 root 54446080 28. Sep 15:16 /flash/data/numbs.dbWriting the whole data set of 1,000,000 rows takes quite a while. The reading of thewhole table into a list object is much faster:In[74]:%25%25timetemp=con.execute('SELECT * FROM numbers').fetchall()printtemp[:2]temp=0.0Out[74]: [(-1.67378, -0.58292, -1.10616, 1.14929, -0.0393), (1.38006, 0.82665, 0         .34168, -1.1676, -0.53274)]",
    "A generally more efficient approach, however, is the reading of either whole tables orquery results with pandas. When you are able to read a whole table into memory, analytical queries can generally be executed much faster than when using the SQLdisk-based approach. The sublibrary pandas.io.sql contains functions to handle data stored in SQL databases:In[77]:importpandas.io.sqlaspdsReading the whole table with pandas takes roughly the same amount of time as readingit into a NumPyndarray object. There as here, the bottleneck is the SQL database:In[78]:%25timedata=pds.read_sql('SELECT * FROM numbers',con)",
    "One of the most widely used formats to exchange data is the CSVformat. Although it isnot really standardized, it can be processed by any platform and the vast majority ofapplications concerned with data and financial analytics. The previous section showshow to write and read data to and from CSV files step by step with standard Pythonfunctionality (cf. %E2%80%9CReading and Writing Text Files%E2%80%9D on page 177). pandasmakes thiswhole procedure a bit more convenient, the code more concise, and the execution ingeneral faster:In[91]:%25timedata.to_csv(filename%2B'.csv')Out[91]: CPU times: user 5.55 s, sys: 137 ms, total: 5.69 s         Wall time: 5.87 sReading the data now stored in the CSV file and plotting it is accomplished with theread_csv function (cf. Figure 7-3 for the result):In[92]:%25%25timepd.read_csv(filename%2B'.csv')[['No1','No2','No3','No4']].hist(bins=20)Out[92]: CPU times: user 1.72 s, sys: 54 ms, total: 1.77 s         Wall time: 1.78 s",
    "Although working with Excel spreadsheets is the topic of a later chapter, we want tobriefly demonstrate how pandas can write data in Excel format and read data fromExcel spreadsheets. We restrict the data set to 100,000 rows in this case:In[93]:%25timedata[:100000].to_excel(filename%2B'.xlsx')Out[93]: CPU times: user 27.5 s, sys: 131 ms, total: 27.6 s         Wall time: 27.7 sGenerating the Excelspreadsheet with this small subset of the data takes quite a while.This illustrates what kind of overhead the spreadsheet structure brings along with it.Reading (and plotting) the data is a faster procedure (cf. Figure 7-4):In[94]:%25timepd.read_excel(filename%2B'.xlsx','Sheet1').cumsum().plot()Out[94]: CPU times: user 12.9 s, sys: 6 ms, total: 12.9 s         Wall time: 12.9 sFigure 7-4. Paths of random data from Excel file",
    "PyTables provides a file-based database format:In[98]:filename=path%2B'tab.h5'h5=tb.open_file(filename,'w')For our example case, we generate a table with 2,000,000 rows of data:In[99]:rows=2000000The table itself has a datetime column, two int columns, and two float columns:In[100]:row_des=%7B'Date':tb.StringCol(26,pos=1),'No1':tb.IntCol(pos=2),",
    "BothpandasandPyTablesareabletoprocesscomplex,SQL-likequeriesandselections.Theyarebothoptimizedforspeedwhenitcomes to such operations.As the following examples show, working with data stored in PyTablesas a Tableobjectmakes you feel like you are working with NumPy and in-memory, both from a syntaxand a performance point of view:In[121]:%25%25timevalues=tab.cols.No3[:]print%22Max %2518.3f%22%25values.max()print%22Ave %2518.3f%22%25values.mean()print%22Min %2518.3f%22%25values.min()print%22Std %2518.3f%22%25values.std()Out[121]: Max              5.152          Ave             -0.000          Min             -5.537          Std              1.000          CPU times: user 44 ms, sys: 39 ms, total: 83 ms          Wall time: 82.6 ms",
    "We have already seen that NumPy has built-in fast writing and reading capabilities forndarray objects. PyTablesis also quite fast and efficient when it comes to storing andretrieving ndarray objects:In[132]:%25%25timearr_int=h5.create_array('/','integers',ran_int)arr_flo=h5.create_array('/','floats',ran_flo)Out[132]: CPU times: user 2 ms, sys: 33 ms, total: 35 ms          Wall time: 35 msWriting these objects directly to an HDF5 database is of course much faster than loopingover the objects and writing the data row-by-row to a Table object. A final inspectionof the database shows now three objects in it, the table and the two arrays:In[133]:h5Out[133]: File(filename=/flash/data/tab.h5, title=u'', mode='w', root_uep='/', f          ilters=Filters(complevel=0, shuffle=False, fletcher32=False, least_sig          nificant_digit=None))          / (RootGroup) u''          /floats (Array(2000000, 2)) ''            atom := Float64Atom(shape=(), dflt=0.0)            maindim := 0            flavor := 'numpy'            byteorder := 'little'            chunkshape := None",
    "SQL-based (i.e., relational) databases have advantages when it comes to complex datastructures that exhibit lots of relations between single objects/tables. This might justifyin some circumstances their performance disadvantage over pure NumPyndarray-basedor pandasDataFrame-based approaches.However, many application areas in finance or science in general, can succeed with amainly array-based data modeling approach. In these cases, huge performance improvements can be realized by making use of native NumPyI/O capabilities, a combina",
    "The paper cited at the beginning of the chapter as well as in the %E2%80%9CConclusions%E2%80%9D sectionis a good read, and a good starting point to think about hardware architecture for financial analytics:%E2%80%A2Appuswamy, Raja et al. (2013): %E2%80%9CNobody Ever Got Fired for Buying a Cluster.%E2%80%9D Microsoft Research, Cambridge, England, http://research.microsoft.com/apps/pubs/default.aspx%3Fid=179615.As usual, the Web provides many valuable resources with regard to the topics coveredin this chapter:",
    "Nowadays, even the most compact notebooks have mainboards with processors thathave multiple cores. Moreover, modern cloud-based computing offerings, like Amazon'sEC2 or Microsoft's Azure, allow for highly scalable, parallel architectures at rather low,variable costs. This brings large-scale computing to the small business, the researcher,and even the ambitious amateur. However, to harness the power of such offerings, appropriate tools are necessary. One such tool is the IPython.parallel library.",
    "With the help of the perf_comp_func function, we can compare the performance a bitmore rigorously:In[46]:n=50# number of option valuationsfunc_list=['seq_value','par_value']data_list=2*['n']In[47]:perf_comp_data(func_list,data_list)Out[47]: function: par_value, av. time sec:   0.90832, relative:    1.0         function: seq_value, av. time sec:   5.75137, relative:    6.3The results clearly demonstrate that using IPython.parallel for parallel execution offunctions can lead to an almost linear scaling of the performance with the number ofcores available.",
    "Many problems in finance allow for the application of simple parallelizationtechniques,forexample,whennodataissharedbetweeninstancesofanalgorithm.ThemultiprocessingmoduleofPythonallows us to efficiently harness the power of modern hardware architectureswithoutingeneralchangingthebasicalgorithmsand/orPython functions to be parallelized.",
    "Numbais an open source, NumPy-aware optimizing compiler for Pythoncode. It uses theLLVM compiler infrastructure1 to compile Python byte code to machine code especiallyfor use in the NumPy runtime and SciPy modules.",
    "Let us start with a problem that typically leads to performance issues in Python: algorithms with nested loops. A sandbox variant can illustrate the problem:In[54]:frommathimportcos,logdeff_py(I,J):res=0foriinrange(I):forjinrange(J):res%2B=int(cos(log(1)))returnresIn a somewhat compute-intensive way, this function returns the total number of loopsgiven the input parameters I and J. Setting both equal to 5,000 leads to 25,000,000 loops:In[55]:I,J=5000,5000%25timef_py(I,J)Out[55]: CPU times: user 17.4 s, sys: 2.3 s, total: 19.7 s         Wall time: 15.2 s         25000000In principle, this can be vectorized with the help of NumPyndarray objects:In[56]:deff_np(I,J):a=np.ones((I,J),dtype=np.float64)returnint(np.sum(np.cos(np.log(a)))),aIn[57]:%25timeres,a=f_np(I,J)Out[57]: CPU times: user 1.41 s, sys: 285 ms, total: 1.69 s         Wall time: 1.65 sThis is much faster, roughly by a factor of 8%E2%80%9310 times, but not really memory-efficient.The ndarray object consumes 200 MB of memory:In[58]:a.nbytesOut[58]: 200000000",
    "Manyapproachesforperformanceimprovements(ofnumericalalgorithms)involveconsiderableeffort.WithPythonandNumbayouhave an approach available that involves only the smallest effort possible-ingeneral,importingthelibraryandasingleadditionallineofcode.Itdoesnotworkforallkindsofalgorithms,butitisoftenwortha (quick) try and sometimes indeed yields a quick win.",
    ": using Numba involves only a little additional effort. The original functionis often not changed at all%3B all you need to do is call the jit function.%E2%80%A2",
    ": Numbaoften leads to significant improvements in execution speed, notonly compared to pure Python but also to vectorized NumPy implementations.%E2%80%A2",
    ": with Numbathere is no need to initialize large array objects%3B the compilerspecializes the machine code to the problem at hand (as compared to the %E2%80%9Cuniversal%E2%80%9Dfunctions of NumPy) and maintains memory efficiency, as with pure Python.",
    "Nowadays, the Python ecosystem provides a number of ways to improve the performance of code:ParadigmsSome Python paradigms might be more performant than others, given a specificproblem.LibrariesThere is a wealth of libraries available for different types of problems, which oftenlead to much higher performance given a problem that fits into the scope of thelibrary (e.g., numexpr).CompilingA number of powerful compiling solutions are available, including static (e.g.,Cython) and dynamic ones (e.g., Numba).ParallelizationSome Python libraries have built-in parallelization capabilities (e.g., numexpr),while others allow us to harness the full power of multiple-core CPUs, whole clusters(e.g., IPython.parallel), or GPUs (e.g., NumbaPro).A major benefit of the Python ecosystem is that all these approaches generally are easilyimplementable, meaning that the additional effort included is generally quite low (evenfor nonexperts). In other words, performance improvements often are low-hangingfruits given the performance libraries available as of today.",
    "To begin with, let us import the libraries that we need for the moment-NumPyandmatplotlib.pyplot:In[1]:importnumpyasnpimportmatplotlib.pyplotasplt%25matplotlibinlineThroughout this discussion, the main example function we will use is the following,which is comprised of a trigonometric term and a linear term:In[2]:deff(x):returnnp.sin(x)%2B0.5*xThe main focus is the approximation of this function over a given interval by regressionand interpolation. First, let us generate a plot of the function to get a better view of whatexactly the approximation shall achieve. The interval of interest shall be [%E2%80%932%ED%9C%8B,2%ED%9C%8B].Figure 9-1 displays the function over the fixed interval defined via the linspace function. np.linspace(start,stop,num) returns num points beginning with startandending with stop, with the subintervals between two consecutive points being evenlyspaced:In[3]:x=np.linspace(-2*np.pi,2*np.pi,50)In[4]:plt.plot(x,f(x),'b')plt.grid(True)plt.xlabel('x')plt.ylabel('f(x)')Figure 9-1. Example function plot",
    "Regression is a rather efficient tool when it comes to function approximation. It is notonly suited to approximate one-dimensional functions but also works well in higher",
    "xx coordinates (independent variable values)yy coordinates (dependent variable values)degDegree of the fitting polynomialfullIf True, returns diagnostic information in additionwWeights to apply to the y coordinatescovIf True, covariance matrix is also returnedIn typical vectorized fashion, the application of polyfit and polyval takes on the following form for a linear regression (i.e., for deg=1):In[5]:reg=np.polyfit(x,f(x),deg=1)ry=np.polyval(reg,x)Given the regression estimates stored in the ry array, we can compare the regressionresult with the original function as presented in Figure 9-2. Of course, a linear regressioncannot account for the sin part of the example function:",
    "Regression can cope equally well with noisy data, be it data from simulation or from(non-perfect) measurements. To illustrate this point, let us generate both independentobservations with noise and also dependent observations with noise:In[23]:xn=np.linspace(-2*np.pi,2*np.pi,50)xn=xn%2B0.15*np.random.standard_normal(len(xn))yn=f(xn)%2B0.25*np.random.standard_normal(len(xn))The very regression is the same:In[24]:reg=np.polyfit(xn,yn,7)ry=np.polyval(reg,xn)Figure 9-7reveals that the regression results are closer to the original function than thenoisy data points. In a sense, the regression averages out the noise to some extent:In[25]:plt.plot(xn,yn,'b%5E',label='f(x)')plt.plot(xn,ry,'ro',label='regression')plt.legend(loc=0)plt.grid(True)plt.xlabel('x')plt.ylabel('f(x)')Figure 9-7. Regression with noisy data",
    "Least-squaresregressionapproacheshavemultipleareasofapplication, including simple function approximation and function approximationbasedonnoisyorunsorteddata.Theseapproachescanbeappliedtosingleaswellasmultidimensionalproblems.Duetotheunderlying mathematics, the application is always %E2%80%9Calmost the same.%E2%80%9D",
    "Compared to regression, interpolation (e.g., with cubic splines), is much more involvedmathematically. It is also limited to low-dimensional problems. Given an ordered set ofobservation points (ordered in the x dimension), the basic idea is to do a regressionbetween two neighboring data points in such a way that not only are the data pointsperfectly matched by the resulting, piecewise-defined interpolation function, but alsothat the function is continuously differentiable at the data points. Continuous differentiability requires at least interpolation of degree 3-i.e., with cubic splines. However,the approach also works in general with quadratic and even linear splines. First, theimporting of the respective sublibrary:In[41]:importscipy.interpolateasspiIn[42]:x=np.linspace(-2*np.pi,2*np.pi,25)We take again the original example function for illustration purposes:In[43]:deff(x):returnnp.sin(x)%2B0.5*x",
    "x(Ordered) x coordinates (independent variable values)y(x-ordered) y coordinates (dependent variable values)wWeights to apply to the y coordinatesxb, xeInterval to fit, if None[x[0], x[-1]]kOrder of the spline fit (1 %3C= k %3C= 5)sSmoothing factor (the larger, the more smoothing)full_outputIf True additional output is returnedquietIf True suppress messagesTable 9-3 lists the parameters that the splev function takes.Table 9-3. Parameters of splev function",
    "x(Ordered) x coordinates (independent variable values)tckSequence of length 3 returned by splrep (knots, coefficients, degree)derOrder of derivative (0 for function, 1 for first derivative)extBehavior if x not in knot sequence (0 extrapolate, 1 return 0, 2 raise ValueError)Applied to the current example, this translates into the following:In[44]:ipo=spi.splrep(x,f(x),k=1)In[45]:iy=spi.splev(x,ipo)As Figure 9-11 shows, the interpolation already seems really good with linear splines(i.e., k=1):In[46]:plt.plot(x,f(x),'b',label='f(x)')plt.plot(x,iy,'r.',label='interpolation')plt.legend(loc=0)plt.grid(True)plt.xlabel('x')plt.ylabel('f(x)')",
    "In those cases where spline interpolation can be applied you can expectbetterapproximationresultscomparedtoaleast-squaresregressionapproach.However,rememberthatyouneedtohavesorted(and%E2%80%9Cnonnoisy%E2%80%9D)dataandthattheapproachislimitedtolow-dimensionalproblems.Itisalsocomputationallymoredemandingandmighttherefore take (much) longer than regression in certain use cases.",
    "In finance and economics, convex optimizationplays an important role. Examples arethe calibration of option pricing models to market data or the optimization of an agent'sutility. As an example function that we want to minimize, we take fm, as defined in thefollowing:In[54]:deffm((x,y)):return(np.sin(x)%2B0.05*x**2%2Bnp.sin(y)%2B0.05*y**2)In[55]:x=np.linspace(-10,10,50)y=np.linspace(-10,10,50)X,Y=np.meshgrid(x,y)Z=fm((X,Y))Figure 9-14shows the function graphically for the defined intervals for x and y. Visualinspection already reveals that this function has multiple local minima. The existenceof a global minimum cannot really be confirmed by this particular graphicalrepresentation:In[56]:fig=plt.figure(figsize=(9,6))ax=fig.gca(projection='3d')surf=ax.plot_surface(X,Y,Z,rstride=2,cstride=2,cmap=mpl.cm.coolwarm,linewidth=0.5,antialiased=True)ax.set_xlabel('x')ax.set_ylabel('y')ax.set_zlabel('f(x, y)')fig.colorbar(surf,shrink=0.5,aspect=5)",
    "To have a closer look behind the scenes when we initiate the minimization procedures,we amend the original function by an option to output current parameter values as wellas the function value:In[58]:deffo((x,y)):z=np.sin(x)%2B0.05*x**2%2Bnp.sin(y)%2B0.05*y**2ifoutput==True:print'%258.4f%258.4f%258.4f'%25(x,y,z)returnzThis allows us to keep track of all relevant information for the procedure, as the followingcode with its respective output illustrates. brutetakes the parameter ranges as input.For example, providing parameter range (-10, 10.1, 5) for the x value will lead to%E2%80%9Ctested%E2%80%9D values of -10, -5, 0, 5, 10:In[59]:output=Truespo.brute(fo,((-10,10.1,5),(-10,10.1,5)),finish=None)Out[59]: -10.0000 -10.0000  11.0880         -10.0000 -10.0000  11.0880         -10.0000  -5.0000   7.7529         -10.0000   0.0000   5.5440         -10.0000   5.0000   5.8351",
    "For the local convex optimization we want to draw on the results from the global optimization. The function fmin takes as input the function to minimize and the startingparameter values. In addition, you can define levels for the input parameter toleranceand the function value tolerance, as well as for the maximum number of iterations andfunction calls:",
    "The integratesublibrary contains a selection of functions to numerically integrate agiven mathematical function given upper and lower integration limits. Examples arefixed_quad for fixed Gaussian quadrature, quad for adaptive quadrature, and rombergfor Romberg integration:In[75]:sci.fixed_quad(f,a,b)[0]Out[75]: 24.366995967084588In[76]:sci.quad(f,a,b)[0]Out[76]: 24.374754718086752In[77]:sci.romberg(f,a,b)Out[77]: 24.374754718086713There are also a number of integration functions that take as input listor ndarrayobjects with function values and input values. Examples in this regard are trapz, usingthe trapezoidal rule, and simps, implementing Simpson's rule:In[78]:xi=np.linspace(0.5,9.5,25)",
    "The previous sections are mainly concerned with numerical computation. This sectionnow introduces symbolic computation, which can be applied beneficially in many areas",
    "SymPy introduces new classes of objects. A fundamental class is the Symbol class:In[83]:x=sy.Symbol('x')y=sy.Symbol('y')In[84]:type(x)Out[84]: sympy.core.symbol.SymbolLike NumPy, SymPy has a number of (mathematical) function definitions. For example:In[85]:sy.sqrt(x)Out[85]: sqrt(x)This already illustrates a major difference. Although x has no numerical value, the squareroot of x is nevertheless defined with SymPysince x is a Symbol object. In that sense,sy.sqrt(x) can be part of arbitrary mathematical expressions. Notice that SymPyingeneral automatically simplifies a given mathematical expression:In[86]:3%2Bsy.sqrt(x)-4**2Out[86]: sqrt(x) - 13Similarly, you can define arbitrary functions using Symbolobjects. They are not to beconfused with Python functions:In[87]:f=x**2%2B3%2B0.5*x**2%2B3/2In[88]:sy.simplify(f)Out[88]: 1.5*x**2 %2B 4SymPy provides three basic renderers for mathematical expressions:%E2%80%A2LaTeX-based%E2%80%A2Unicode-based%E2%80%A2ASCII-basedWhen working, for example, solely in the IPythonNotebook, LaTeXrendering is generally a good (i.e., visually appealing) choice. In what follows, we stick to the simplestoption, ASCII, to illustrate that there is no handmade type setting involved:In[89]:sy.init_printing(pretty_print=False,use_unicode=False)In[90]:printsy.pretty(f)",
    "A strength of SymPy is solving equations, e.g., of the form x2 %E2%80%93 1 = 0:In[95]:sy.solve(x**2-1)Out[95]: [-1, 1]In general, SymPy presumes that you are looking for a solution to the equation obtainedby equating the given expression to zero. Therefore, equations like x2 %E2%80%93 1 = 3 might haveto be reformulated to get the desired result:In[96]:sy.solve(x**2-1-3)Out[96]: [-2, 2]Of course, SymPy can cope with more complex expressions, like x3 %2B 0.5x2 %E2%80%93 1 = 0:In[97]:sy.solve(x**3%2B0.5*x**2-1)Out[97]: [0.858094329496553, -0.679047164748276 - 0.839206763026694*I,         -0.679047164748276 %2B 0.839206763026694*I]",
    "Another strength of SymPyis integration and differentiation. In what follows, we revisitthe example function used for numerical- and simulation-based integration and derivenow both a symbolic and a numerically exact solution. We need symbols for the integration limits:In[99]:a,b=sy.symbols('a b')Having defined the new symbols, we can %E2%80%9Cpretty print%E2%80%9D the symbolic integral:In[100]:printsy.pretty(sy.Integral(sy.sin(x)%2B0.5*x,(x,a,b)))Out[100]:   b            /           %7C           %7C  (0.5*x %2B sin(x)) dx           %7C          /          aUsing integrate, we can then derive the antiderivative of the integration function:In[101]:int_func=sy.integrate(sy.sin(x)%2B0.5*x,x)In[102]:printsy.pretty(int_func)Out[102]:       2          0.25*x  - cos(x)Equipped with the antiderivative, the numerical evaluation of the integral is only threesteps away. To numerically evaluate a SymPyexpression, replace the respective symbolwith the numerical value using the method subsand call the method evalfon the newexpression:In[103]:Fb=int_func.subs(x,9.5).evalf()Fa=int_func.subs(x,0.5).evalf()The difference between Fb and Fa then yields the exact integral value:In[104]:Fb-Fa# exact value of integral",
    "The derivative of the antiderivative shall yield in general the original function. Let uscheck this by applying the diff function to the symbolic antiderivative from before:In[108]:int_func.diff()Out[108]: 0.5*x %2B sin(x)As with the integration example, we want to use differentiation now to derive the exactsolution of the convex minimization problem we looked at earlier. To this end, we definethe respective function symbolically as follows:In[109]:f=(sy.sin(x)%2B0.05*x**2%2Bsy.sin(y)%2B0.05*y**2)For the minimization, we need the two partial derivatives with respect to both variables,x and y:In[110]:del_x=sy.diff(f,x)del_xOut[110]: 0.1*x %2B cos(x)In[111]:del_y=sy.diff(f,y)del_yOut[111]: 0.1*y %2B cos(y)A necessary but not sufficient condition for a global minimum is that both partial derivatives are zero. As stated before, there is no guarantee of a symbolic solution. Bothalgorithmic and (multiple) existence issues come into play here. However, we can solve",
    "WhendoingmathematicswithPython,youshouldalwaysthinkofSymPyandsymboliccomputations.Especiallyforinteractivefinancialanalytics,thiscanbeamoreefficientapproachcomparedtonon-symbolic approaches.",
    "This chapter covers some mathematical topics and tools important to finance. For example, the approximation of functions is important in many financial areas, like yieldcurve interpolation and regression-based Monte Carlo valuation approaches for American options. Convex optimizationtechniques are also regularly needed in finance%3B forexample, when calibrating parametric option pricing models to market quotes or implied volatilities of options.",
    "For further information on the Python libraries used in this chapter, you should consultthe following web resources:%E2%80%A2See http://docs.scipy.org/doc/numpy/reference/ for all functions used from NumPy.%E2%80%A2The statsmodels library is documented here: http://statsmodels.sourceforge.net.%E2%80%A2Visit http://docs.scipy.org/doc/scipy/reference/optimize.html for details on scipy.optimize.%E2%80%A2Integration with scipy.integrate is explained here: http://docs.scipy.org/doc/scipy/reference/integrate.html.%E2%80%A2The home of SymPy is http://sympy.org.For a good reference to the mathematical topics covered, see:%E2%80%A2Brandimarte, Paolo (2006): Numerical Methods in Finance and Economics, 2nd ed.John Wiley %26 Sons, Hoboken, NJ.",
    "Throughout this chapter, to generate random numbers1 we will work with the functionsprovided by the numpy.random sublibrary:In[1]:importnumpyasnpimportnumpy.randomasnprimportmatplotlib.pyplotasplt%25matplotlibinlineFor example, the randfunction returns random numbers from the open interval [0,1)in the shape provided as a parameter to the function. The return object is an ndarrayobject:In[2]:npr.rand(10)Out[2]: array([ 0.40628966,  0.43098644,  0.9435419 ,  0.26760198,  0.2729951 ,                0.67519064,  0.41349754,  0.3585647 ,  0.07450132,  0.95130158])In[3]:npr.rand(5,5)Out[3]: array([[ 0.87263851,  0.8143348 ,  0.34154499,  0.56695052,  0.60645041],               [ 0.39398181,  0.71671577,  0.63568321,  0.61652708,  0.93526172],               [ 0.12632038,  0.35793789,  0.04241014,  0.88085228,  0.54260211],               [ 0.14503456,  0.32939077,  0.28834351,  0.4050322 ,  0.21120017],               [ 0.45345805,  0.29771411,  0.67157606,  0.73563706,  0.48003387]        ])Such numbers can be easily transformed to cover other intervals of the real line. Forinstance, if you want to generate random numbers from the interval [a,b)=[5,10), youcan transform the returned numbers from rand as follows:In[4]:a=5.b=10.npr.rand(10)*(b-a)%2BaOut[4]: array([ 7.27123881,  6.51309437,  7.51380629,  7.84258434,  7.62199611,                8.86229349,  6.78202851,  6.33248656,  8.10776244,  9.48668419])This also works for multidimensional shapes due to NumPy broadcasting:In[5]:npr.rand(5,5)*(b-a)%2Ba",
    " with mean of 0 and standard deviation of 1%E2%80%A2",
    " with mean of 100 and standard deviation of 20%E2%80%A2",
    " with 0.5 degrees of freedom%E2%80%A2",
    " with lambda of 1We do this as follows:In[8]:sample_size=500rn1=npr.standard_normal(sample_size)rn2=npr.normal(100,20,sample_size)rn3=npr.chisquare(df=0.5,size=sample_size)rn4=npr.poisson(lam=1.0,size=sample_size)Figure 10-2 shows the results for the three continuous distributions and the discreteone (Poisson). The Poisson distribution is used, for example, to simulate the arrival of(rare) external events, like a jump in the price of an instrument or an exogenic shock.Here is the code that generates it:In[9]:fig,((ax1,ax2),(ax3,ax4))=plt.subplots(nrows=2,ncols=2,figsize=(7,7))ax1.hist(rn1,bins=25)ax1.set_title('standard normal')ax1.set_ylabel('frequency')ax1.grid(True)ax2.hist(rn2,bins=25)ax2.set_title('normal(100, 20)')ax2.grid(True)ax3.hist(rn3,bins=25)ax3.set_title('chi square')ax3.set_ylabel('frequency')ax3.grid(True)ax4.hist(rn4,bins=25)ax4.set_title('Poisson')ax4.grid(True)",
    "Monte Carlo simulation (MCS) is among the most important numerical techniques infinance, if not the most important and widely used. This mainly stems from the fact thatit is the most flexible numerical method when it comes to the evaluation of mathematicalexpressions (e.g., integrals), and specifically the valuation of financial derivatives. Theflexibility comes at the cost of a relatively high computational burden, though, sinceoften hundreds of thousands or even millions of complex computations have to becarried out to come up with a single value estimate.",
    "Consider, for example, the Black-Scholes-Merton setup for option pricing (cf. alsoChapter 3). In their setup, the level of a stock index STat a future date Tgiven a level S0as of today is given according to Equation 10-1.Equation 10-1. Simulating future index level in Black-Scholes-Merton setupST=S0expr%E2%88%9212%CF%832T%2B%CF%83TzThe variables and parameters have the following meaning:",
    "Roughly speaking, a stochastic processis a sequence of random variables. In that sense,we should expect something similar to a sequence of repeated simulations of a randomvariable when simulating a process. This is mainly true, apart from the fact that thedraws are in general not independent but rather depend on the result(s) of the previousdraw(s). In general, however, stochastic processes used in finance exhibit the Markovproperty, which mainly says that tomorrow's value of the process only depends on today'sstate of the process, and not any other more %E2%80%9Chistoric%E2%80%9D state or even the whole pathhistory. The process then is also called memoryless.",
    "Another important class of financial processes is mean-reverting processes, which areused to model short rates or volatility processes, for example. A popular and widely usedmodel is the square-root diffusion, as proposed by Cox, Ingersoll, and Ross (1985).Equation 10-4 provides the respective SDE.Equation 10-4. Stochastic differential equation for square-root diffusiondxt=%CE%BA%CE%B8%E2%88%92xtdt%2B%CF%83xtdZt",
    "One of the major simplifying assumptions of the Black-Scholes-Merton model is theconstantvolatility. However, volatility in general is neither constant nor deterministic%3Bit is stochastic. Therefore, a major advancement with regard to financial modeling wasachieved in the early 1990s with the introduction of so-called stochastic volatility models. One of the most popular models that fall into that category is that of Heston (1993),which is presented in Equation 10-7.",
    "Stochastic volatility and the leverage effect are stylized (empirical) facts found in anumber of markets. Another important stylized empirical fact is the existence of jumpsin asset prices and, for example, volatility. In 1976, Merton published his jump diffusionmodel, enhancing the Black-Scholes-Merton setup by a model component generatingjumps with log-normal distribution. The risk-neutral SDE is presented inEquation 10-8.Equation 10-8. Stochastic differential equation for Merton jump diffusion modeldSt = (r %E2%80%93 rJ)Stdt %2B %ED%9C%8EStdZt %2B JtStdNtFor completeness, here is an overview of the variables' and parameters' meaning:StIndex level at date trConstant riskless short raterJ%E2%89%A1%CE%BB%C2%B7e%CE%BCJ%2B%CE%B42/2%E2%88%921Drift correction for jump to maintain risk neutrality%CF%83Constant volatility of SZtStandard Brownian motionJtJump at date t with distribution %E2%80%A6%E2%80%A2%E2%80%A6 log1%2BJt%E2%89%88%ED%90%80log1%2B%CE%BCJ%E2%88%92%CE%B422,%CE%B42 with %E2%80%A6%E2%80%A2%E2%80%A6 ",
    "Not only because of the fact that the Python functions we have used so far generatepseudorandom numbers, but also due to the varying sizes of the samples drawn, resultingsets of numbers might not exhibit statistics really close enough to the expected/desiredones. For example, you would expect a set of standard normally distributed randomnumbers to show a mean of 0 and a standard deviation of 1. Let us check what statistics",
    "One of the most important applications of Monte Carlo simulation is the valuation ofcontingent claims (options, derivatives, hybrid instruments, etc.). Simply stated, in arisk-neutral world, the value of a contingent claim is the discounted expected payoffunder the risk-neutral (martingale) measure. This is the probability measure that makesall risk factors (stocks, indices, etc.) drift at the riskless short rate. According to theFundamental Theorem of Asset Pricing, the existence of such a probability measure isequivalent to the absence of arbitrage.",
    "The payoff of a European call option on an index at maturity is given by h(ST) %E2%89%A1max(ST %E2%80%93 K,0), where STis the index level at maturity date T and Kis the strike price.Given a, or in complete markets the, risk-neutral measure for the relevant stochasticprocess (e.g., geometric Brownian motion), the price of such an option is given by theformula in Equation 10-10.Equation 10-10. Pricing by risk-neutral expectation C 0=e%E2%88%92rT%ED%90%800QhST=e%E2%88%92rT0%E2%88%9EhsqsdsChapter 9 briefly sketches how to numerically evaluate an integral by Monte Carlosimulation. This approach is used in the following and applied to Equation 10-10.Equation 10-11 provides the respective Monte Carlo estimator for the European option,where S%CB%9CTi is the ith simulated index level at maturity.Equation 10-11. Risk-neutral Monte Carlo estimator C 0%CB%9C=e%E2%88%92rT1I%E2%88%91i=1IhS%CB%9CTiConsider now the following parameterization for the geometric Brownian motion andthe valuation function gbm_mcs_stat, taking as a parameter only the strike price. Here,only the index level at maturity is simulated:In[56]:S0=100.r=0.05sigma=0.25T=1.0I=50000defgbm_mcs_stat(K):''' Valuation of European call option in Black-Scholes-Merton             by Monte Carlo simulation (of index level at maturity)             Parameters             ==========",
    "The valuation of American options is more involved compared to European options.In this case, an optimal stopping problem has to be solved to come up with a fair valueof the option. Equation 10-12formulates the valuation of an American option as sucha problem. The problem formulation is already based on a discrete time grid for usewith numerical simulation. In a sense, it is therefore more correct to speak of an optionvalue given Bermudan exercise. For the time interval converging to zero length, thevalue of the Bermudan option converges to the one of the American option.Equation 10-12. American option prices as optimal stopping problemV0=sup%CF%84%E2%88%880,%CE%94t,2%CE%94t,...,Te%E2%88%92rT%ED%90%800Qh%CF%84S%CF%84The algorithm we describe in the following is called Least-Squares Monte Carlo (LSM)and is from the paper by Longstaff and Schwartz (2001). It can be shown that the valueof an American (Bermudan) option at any given date t is given as Vt(s) =max(ht(s), C t(s)), where  C ts=%ED%90%80tQe%E2%88%92r%CE%94tVt%2B%CE%94tSt%2B%CE%94tSt=s is the so-called continuationvalue of the option given an index level of St = s.Consider now that we have simulated Ipaths of the index level over Mtime intervals ofequal size %CE%94t. Define Yt,i%E2%89%A1e%E2%80%93r%ED%9B%A5tVt%2B%ED%9B%A5t,ito be the simulated continuation value for path i attime t. We cannot use this number directly because it would imply perfect foresight.",
    "In addition to valuation, risk managementis another important application area of stochastic methods and simulation. This section illustrates the calculation/estimation oftwo of the most common risk measures applied today in the finance industry.",
    "Value-at-risk (VaR) is one of the most widely used risk measures, and a much debatedone. Loved by practitioners for its intuitive appeal, it is widely discussed and criticizedby many-mainly on theoretical grounds, with regard to its limited ability to capturewhat is called tail risk (more on this shortly). In words, VaR is a number denoted incurrency units (e.g., USD, EUR, JPY) indicating a loss (of a portfolio, a single position,etc.) that is not exceeded with some confidence level (probability) over a given periodof time.Consider a stock position, worth 1 million USD today, that has a VaR of 50,000 USD ata confidence level of 99%25 over a time period of 30 days (one month). This VaR figuresays that with a probability of 99%25 (i.e., in 99 out of 100 cases), the loss to be expectedover a period of 30 days will not exceed50,000 USD. However, it does not say anythingabout the size of the loss once a loss beyond 50,000 USD occurs-i.e., if the maximumloss is 100,000 or 500,000 USD what the probability of such a specific %E2%80%9Chigher than VaRloss%E2%80%9D is. All it says is that there is a 1%25 probability that a loss of a minimum of 50,000USD or higher will occur.",
    "This chapter deals with methods and techniques important to the application of MonteCarlo simulation in finance. In particular, it shows how to generate (pseudo)randomnumbers based on different distribution laws. It proceeds with the simulation of randomvariables and stochastic processes, which is important in many financial areas. Two application areas are discussed in some depth in this chapter: valuation of optionswithEuropean and American exercise and the estimation of risk measures like value-at-riskand credit value adjustments.The chapter illustrates that Pythonin combination with NumPyis well suited to implementing even such computationally demanding tasks as the valuation of American options by Monte Carlo simulation. This is mainly due to the fact that the majority offunctions and classes of NumPy are implemented in  C , which leads to considerable speedadvantages in general over pure Pythoncode. A further benefit is the compactness andreadability of the resulting code due to vectorized operations.",
    "The original article introducing Monte Carlo simulation to finance is:",
    "The normal distributioncan be considered the most important distribution in financeand one of the major statistical building blocks of financial theory. Among others, thefollowing cornerstones of financial theory rest to a large extent on the normal distribution of stock market returns:Portfolio theoryWhen stock returns are normally distributed, optimal portfolio choice can be castinto a setting where only the mean return and the variance of the returns(or thevolatility) as well as the covariances between different stocks are relevant for aninvestment decision (i.e., an optimal portfolio composition).Capital asset pricing modelAgain, when stock returns are normally distributed, prices of single stocks can beelegantly expressed in relationship to a broad market index%3B the relationship isgenerally expressed by a measure for the comovement of a single stock with themarket index called beta (%ED%9B%BD).Efficient markets hypothesisAn efficient market is a market where prices reflect all available information, where%E2%80%9Call%E2%80%9D can be defined more narrowly or more widely (e.g., as in %E2%80%9Call publicly available%E2%80%9Dinformation vs. including also %E2%80%9Conly privately available%E2%80%9D information)%3B if this hypothesis holds true, then stock prices fluctuate randomly and returns are normallydistributed.",
    "To set the stage for further analyses, we start with the geometric Brownian motion asone of the canonical stochastic processes used in financial modeling. The following canbe said about the characteristics of paths from a geometric Brownian motion S:Normal log returnsLog returns logStSs=logSt%E2%88%92logSs between two times 0 %3C s%3C tare normallydistributed.Log-normal valuesAt any time t %3E 0, the values St are log-normally distributed.For what follows we need a number of Python libraries, including scipy.statsandstatsmodels.api:In[1]:importnumpyasnpnp.random.seed(1000)importscipy.statsasscsimportstatsmodels.apiassmimportmatplotlibasmplimportmatplotlib.pyplotasplt%25matplotlibinlineLet us define a function to generate Monte Carlo paths for the geometric Brownianmotion (see also Chapter 10):In[2]:defgen_paths(S0,r,sigma,T,M,I):''' Generates Monte Carlo paths for geometric Brownian motion.            Parameters            ==========            S0 : float                initial stock/index value            r : float                constant short rate            sigma : float                constant volatility            T : float                final time horizon            M : int",
    "Thenormalityassumptionwithregardtoreturnsofsecuritiesiscentraltoanumberofimportantfinancialtheories.Pythonprovidesefficientstatisticalandgraphicalmeanstotestwhethertimeseriesdata is normally distributed or not.",
    "We are now pretty well equipped to attack real-world data and see how the normalityassumption does beyond the financial laboratory. We are going to analyze four historicaltime series: two stock indices (the German DAX index and the American S%26P 500 index)and two stocks (Yahoo! Inc. and Microsoft Inc.). The data management tool of choiceis pandas (cf. Chapter 6), so we begin with a few imports:In[21]:importpandasaspdimportpandas.io.dataaswebHere are the symbols for the time series we are interested in. The curious reader mightof course replace these with any other symbol of interest:In[22]:symbols=['%5EGDAXI','%5EGSPC','YHOO','MSFT']The following reads only the Adj Closetime series data into a single DataFrame objectfor all symbols:In[23]:data=pd.DataFrame()forsyminsymbols:data[sym]=web.DataReader(sym,data_source='yahoo',start='1/1/2006')['Adj Close']data=data.dropna()In[24]:data.info()",
    "Modern or mean-variance portfolio theory (MPT) is a major cornerstone of financialtheory. Based on this theoretical breakthrough the Nobel Prize in Economics was awarded to its inventor, Harry Markowitz, in 1990. Although formulated in the 1950s,1 it isstill a theory taught to finance students and applied in practice today (often with someminor or major modifications). This section illustrates the fundamental principles ofthe theory.",
    "Let us begin our Pythonsession by importing a couple of by now well-known libraries:In[33]:importnumpyasnpimportpandasaspdimportpandas.io.dataaswebimportmatplotlib.pyplotasplt%25matplotlibinlineWe pick five different assets for the analysis: American tech stocks Apple Inc., Yahoo!Inc., and Microsoft Inc., as well as German Deutsche Bank AG and gold as a commodityvia an exchange-traded fund (ETF). The basic idea of MPT is diversification to achievea minimal portfolio risk or maximal portfolio returns given a certain level of risk. Onewould expect such results for the right combination of a large enough number of assetsand a certain diversity in the assets. However, to convey the basic ideas and to showtypical effects, these five assets shall suffice:In[34]:symbols=['AAPL','MSFT','YHOO','DB','GLD']noa=len(symbols)Using the DataReader function of pandas (cf. Chapter 6) makes getting the time seriesdata rather efficient. We are only interested, as in the previous example, in the Closeprices of each stock:In[35]:data=pd.DataFrame()forsyminsymbols:data[sym]=web.DataReader(sym,data_source='yahoo',end='2014-09-12')['Adj Close']data.columns=symbolsFigure 11-11 shows the time series data in normalized fashion graphically:In[36]:(data/data.ix[0]*100).plot(figsize=(8,5))",
    "%E2%80%9CIn what follows, we assume that an investor is not allowed to set up short positions ina security. Only long positions are allowed, which means that 100%25 of the investor's",
    "TheMPTexampleshowsagainhowefficientitiswithPythontotranslatemathematicalconcepts,likeportfolioreturnorportfoliovariance,intoexecutable,vectorizedcode(anargumentmadeinChapter 1).",
    "The derivation of all optimal portfolios-i.e., all portfolios with minimum volatility fora given target return level (or all portfolios with maximum return for a given risk level)-is similar to the previous optimizations. The only difference is that we have to iterateover multiple starting conditions. The approach we take is that we fix a target returnlevel and derive for each such level those portfolio weights that lead to the minimumvolatility value. For the optimization, this leads to two conditions: one for the targetreturn level tretand one for the sum of the portfolio weights as before. The boundaryvalues for each parameter stay the same:In[62]:cons=(%7B'type':'eq','fun':lambdax:statistics(x)[0]-tret%7D,%7B'type':'eq','fun':lambdax:np.sum(x)-1%7D)bnds=tuple((0,1)forxinweights)",
    "In addition to risky securities like stocks or commodities (such as gold), there is ingeneral one universal, riskless investment opportunity available: cash or cash accounts.In an idealized world, money held in a cash account with a large bank can be consideredriskless (e.g., through public deposit insurance schemes). The downside is that such ariskless investment generally yields only a small return, sometimes close to zero.However, taking into account such a riskless asset enhances the efficient investmentopportunity set for investors considerably. The basic idea is that investors first determinean efficient portfolio of risky assets and then add the riskless asset to the mix. By adjusting the proportion of the investor's wealth to be invested in the riskless asset it ispossible to achieve any risk-return profile that lies on the straight line (in the risk-returnspace) between the riskless asset and the efficient portfolio.Which efficient portfolio (out of the many options) is to be taken to invest in optimalfashion%3F It is the one portfolio where the tangent line of the efficient frontier goes exactlythrough the risk-return point of the riskless portfolio. For example, consider a risklessinterest rate of rf = 0.01. We look for that portfolio on the efficient frontier for whichthe tangent goes through the point (%ED%9C%8Ef,rf) = (0,0.01) in risk-return space.For the calculations to follow, we need a functional approximation and the first derivative for the efficient frontier. We use cubic splines interpolation to this end (cf.Chapter 9):In[66]:importscipy.interpolateassci",
    "Usually, PCA works with normalized data sets. Therefore, the following conveniencefunction proves helpful:In[6]:scale_function=lambdax:(x-x.mean())/x.std()For the beginning, consider a PCA with multiple components (i.e., we do not restrictthe number of components):3In[7]:pca=KernelPCA().fit(data.apply(scale_function))The importance or explanatory power of each component is given by its Eigenvalue.These are found in an attribute of the KernelPCA object. The analysis gives too manycomponents:In[8]:len(pca.lambdas_)Out[8]: 655Therefore, let us only have a look at the first 10 components. The tenth componentalready has almost negligible influence:In[9]:pca.lambdas_[:10].round()Out[9]: array([ 22816.,   6559.,   2535.,   1558.,    697.,    442.,    378.,                  255.,    183.,    151.])We are mainly interested in the relative importance of each component, so we willnormalize these values. Again, we use a convenience function for this:In[10]:get_we=lambdax:x/x.sum()In[11]:get_we(pca.lambdas_)[:10]Out[11]: array([ 0.6295725 ,  0.1809903 ,  0.06995609,  0.04300101,  0.01923256,                 0.01218984,  0.01044098,  0.00704461,  0.00505794,  0.00416612])With this information, the picture becomes much clearer. The first component alreadyexplains about 60%25 of the variability in the 30 time series. The first five componentsexplain about 95%25 of the variability:In[12]:get_we(pca.lambdas_)[:5].sum()",
    "Bayesian statistics nowadays is a cornerstone in empirical finance. This chapter cannotlay the foundations for all concepts of the field. You should therefore consult, if needed,a textbook like that by Geweke (2005) for a general introduction or Rachev (2008) forone that is financially motivated.",
    ": p(D) = 0.5 %C2%B7 0.2 %2B 0.5 %C2%B7 0.4 = 0.3%E2%80%A2",
    ": p(D%7CH1) = 0.2This gives for the updated probability of H1pH1D=0.5%C2%B70.20.3=13.This result also makes sense intuitively. The probability for drawing a black ball frombox B2 is twice as high as for the same event happening with box B1. Therefore, havingdrawn a black ball, the hypothesis H2has with pH2D=23an updated probability twotimes as high as the updated probability for hypothesis H1.",
    "Consider now an example where we have noisy data around a straight line:5In[23]:x=np.linspace(0,10,500)y=4%2B2*x%2Bnp.random.standard_normal(len(x))*2As a benchmark, consider first an ordinary least-squares regression given the noisy data,using NumPy's polyfit function (cf. Chapter 9). The regression is implemented asfollows:In[24]:reg=np.polyfit(x,y,1)# linear regressionFigure 11-19 shows the data and the regression line graphically:In[25]:plt.figure(figsize=(8,4))plt.scatter(x,y,c=y,marker='v')plt.plot(x,reg[1]%2Breg[0]*x,lw=2.0)plt.colorbar()plt.grid(True)plt.xlabel('x')plt.ylabel('y')",
    "Statistics is not only an important discipline in its own right, but also provides indispensible tools for many other disciplines, like finance and the social sciences. It is impossible to give a broad overview of statistics in a single chapter. This chapter thereforeconcentrates on four important topics, illustrating the use of Python and several statisticslibraries on the basis of realistic examples:Normality testsThe normality assumption with regard to financial market returns is an importantone for many financial theories and applications%3B it is therefore important to be ableto test whether certain time series data conforms to this assumption. As we haveseen-via graphical and statistical means-real-world return data generally is notnormally distributed.Modern portfolio theoryMPT, with its focus on the mean and variance/volatility of returns, can be considered one of the major conceptual and intellectual successes of statistics in finance%3Bthe important concept of investment diversificationis beautifully illustrated in thiscontext.Principal component analysisPCA provides a pretty helpful method to reduce complexity for factor/componentanalysis tasks%3B we have shown that five principal components-constructed fromthe 30 stocks contained in the DAX index-suffice to explain more than 95%25 of theindex's variability.Bayesian regressionBayesian statistics in general (and Bayesian regression in particular) has become apopular tool in finance, since this approach overcomes shortcomings of other approaches, as introduced in Chapter 9%3B even if the mathematics and the formalismare more involved, the fundamental ideas-like the updating of probability/distribution beliefs over time-are easily grasped intuitively.",
    "The following online resources are helpful:",
    "XL_CELL_EMPTY0Empty stringXL_CELL_TEXT1A Unicode stringXL_CELL_NUMBER2floatXL_CELL_DATE3floatXL_CELL_BOOLEAN4int (1 = TRUE, 0 = FALSE)XL_CELL_ERROR5int representing internal Excel codesXL_CELL_BLANK6Empty string, only when formatting_info=TrueSimilarly, you can access whole rows by providing the number of the row to the rowmethod:In[27]:sheet_2.row(3)Out[27]: [number:25.0,          number:26.0,          number:27.0,          number:28.0,          number:29.0,          number:30.0,",
    "There is yet another library to generate and read Excel spreadsheet files in .xlsxformatwith Python: OpenPyxl. This library allows us to both create spreadsheet files and readfrom them. In addition, while basic usage is similar to the other libraries, the interfaceis in some cases a bit more Pythonic and might therefore be worth taking a look at.Import the library as follows:In[32]:importopenpyxlasoxl",
    "DataNitroworks on Windows operating systems and Excelinstallations only. On MacOS systems it can be used in a Windows virtual machine environment. It is compatible",
    "rowRow of the cellcolColumn of the cellpositionPosition as a (row,col) tuplesheetName of the sheet the cell is innameName of the cell in Excel fashionvalueValue of the cellverticalAll cell values including and below the cellvertical_rangeExcel range for all cells including and below the cellhorizontalAll cell values including and right of the cellhorizontal_rangeExcel range for all cells including and right of the celltableAll values including and below/right of the cell as nested list objecttable_rangeExcel range for table objectformulaExcel formulacommentComment attached to cellhyperlinkHyperlink or email address as string objectalignmentText/value alignment for displaycolorCell colordfLets you write a pandasDataFrame object directly to the spreadsheetTable 12-3shows typesetting options for the Cellobject. All options are attributes ofthe font object, which is a property of the Cell object. For example, this:Cell(%22A1%22).font.size = 15sets a (new) font size.Table 12-3. DataNitro Cell typesetting options",
    "sizeFont sizecolorFont colorboldBold font via Cell(%22A1%22).font.bold=TrueitalicItalic fontunderlineUnderlines textstrikethroughPuts strikethrough line through textsubscriptSubscripts textsuperscriptSuperscripts text",
    "clearResets all properties/attributes of the cellcopy_fromCopies all properties/attributes from another cellcopy_format_fromCopies all properties/attributes from another cell except value and formulais_emptyReturns True if emptyoffsetReturns cell object given relative offset as (row,col) tuplesubtractionSubtraction gives the offset%3B e.g., Cell(%22B4%22) - Cell(%22A2%22) gives (2, 1)printGives name and sheet of cellset_nameSets named range in Excel%3B e.g., Cell(%22A1%22).set_name(%22upper_left%22)Often, it is helpful to work with CellRange instead of Cellobjects only. One can thinkof this as an approach to vectorize certain operations on multiple Cell objects. Considerthe following examples, still based on the same spreadsheet file workbook.xlsxwithour previous changes:In[6]:CellRange(%22A1:A8%22).valueOut[6]:[1,2,3,4,5,6,7,8]In[7]:CellRange(%22A1:A8%22).value=1# like broadcastingIn[8]:CellRange(%22A1:A8%22).valueOut[8]:[1,1,1,1,1,1,1,1]In[9]:CellRange(%22A1:A8%22).value=2*[1,2,3,4]In[10]:CellRange(%22A1:A8%22).valueOut[10]:[1,2,3,4,1,2,3,4]In[11]:Cell(%22A9%22).valueOut[11]:20# value of Sum function is# automatically updatedOf course, you can also use CellRange for iteration:In[12]:forcellinCellRange(%22A1:B2%22):....:printcell.name,cell.value....:A11B1PythonwithExcelA22B210",
    "From a finance point of view, it seems most interesting to expose user-defined functions(UDFs) via DataNitro to Excel. This option has to be enabled in the Settings menuof DataNitro. Once this is enabled, you can import a Python script with DataNitrocalled functions.py. All Pythonfunctions included in this file-and they have to be inthis particular file-will then be directly callable from Excel. Consider the by now well-known function to value European call options in the Black-Scholes-Merton model inExample 12-2.Example 12-2. Python script for import with DataNitro into Excel## Valuation of European call options in BSM model# for use with DataNitro and Excel spreadsheets# functions.py## analytical Black-Scholes-Merton (BSM) formuladefbsm_call_value(S0,K,T,r,sigma):''' Valuation of European call option in BSM model.    Analytical formula.    Parameters    ==========    S0 : float        initial stock/index level",
    "At the time of this writing, a new contender in the Python-Excelintegration world hasemerged: xlwings. xlwings provides almost all the functionality for interacting withand scripting Excel spreadsheets with Python. It is, in contrast to the DataNitro solution, an open source library and can be freely shipped with any spreadsheet. The receiverof an xlwings%E2%80%9Cpowered%E2%80%9D spreadsheet only needs a (minimal) Python installation. Oneadvantage of xlwings is that it works with Excel both on Windows and Apple/Macoperating systems. In addition, it is well documented, although it is only in early release(0.3 at the time of this writing). The whole solution and approach look promising. andanybody interested in integrating Python and Excel should give it a try.",
    "There are several options to integrate Python with Excel. Some Python libraries-likexlwt or xlsxwriter-allow the creation of Excel spreadsheets. Other libraries like xlrdallow the reading of arbitrary spreadsheet files, or they allow both reading and writingof spreadsheet files.",
    "For all libraries and solutions presented in this chapter, there are helpful web resourcesavailable:%E2%80%A2For xlrd and xlwt, see http://www.python-excel.orgfor the online documentation%3Bthere is also a tutorial available in PDFformat at http://www.simplistix.co.uk/presentations/python-excel.pdf.%E2%80%A2xlsxwriteris nicely documented on the website http://xlsxwriter.readthedocs.org.%E2%80%A2OpenPyxl has its home here: http://pythonhosted.org/openpyxl/.%E2%80%A2For detailed information about PyXLL, see https://www.pyxll.com.%E2%80%A2Free trials and detailed documentation for DataNitro can be found at http://www.datanitro.com.%E2%80%A2You can find the documentation and everything else you need regarding xlwingsat http://xlwings.org.",
    "Wikipedia provides the following definition for object-oriented programming:Object-oriented programming (OOP) is a programming paradigm that represents concepts as %E2%80%9Cobjects%E2%80%9D that have data fields (attributes that describe the object) and associatedprocedures known as methods. Objects, which are usually instances of classes, are usedto interact with one another to design applications and computer programs.",
    "So far, the new short_rate class using traits allows us to input data for initializingattributes of an instance of the class. However, a GUI usually is also used to presentresults. You would generally want to avoid providing input data via a GUI and thenmaking the user access the results via interactive scripting. To this end, we need anothersublibrary, traitsui.api:In[80]:importtraits.apiastrapiimporttraitsui.apiastruiThis sublibrary allows us to generate different views on the same class/object. It alsoprovides more options for, e.g., labeling and formatting. The key in the following classdefinition is what happens when the Updatebutton is pushed. In this case, the privatemethod %5C_update%5C_firedis called, which updates the list object containing the discount factors. This updated list is then displayed in the GUI window. A prerequisite forthis is that all input parameters have been made available by the user:In[81]:classshort_rate(trapi.HasTraits):name=trapi.Strrate=trapi.Floattime_list=trapi.Array(dtype=np.float,shape=(1,5))disc_list=trapi.Array(dtype=np.float,shape=(1,5))update=trapi.Buttondef_update_fired(self):self.disc_list=np.exp(-self.rate*self.time_list)v=trui.View(trui.Group(trui.Item(name='name'),trui.Item(name='rate'),trui.Item(name='time_list',label='Insert Time List Here'),trui.Item('update',show_label=False),trui.Item(name='disc_list',label='Press Update for Factors'),",
    "Object-oriented paradigms are an indispensible tool for modern application development. Python provides a rather flexible framework for the definition of customer-defined classes and for working with instances of these classes. This chapter providesonly the fundamentals of Python class definitions-Part IIIof the book illustrates theuse of (financial) Python classes in a more complex and realistic application scenario.Modern application design generally builds on graphicaluser interfaces. The efficientbuilding of GUIs therefore is generally quite important, even in a rapid applicationdevelopment scenario. This chapter uses the traits library, which allows simple andefficient building of GUIs based on a Pythonic, object-oriented approach. Thesubsequent chapter shows how to build GUIs based on web technologies, a technicalalternative nowadays even used for in-house applications in financial institutions.",
    "The following web resources are good starting points for Python classes and objectorientation, and for traits:%E2%80%A2The Python class documentation: https://docs.python.org/2/tutorial/classes.html",
    "This section gives a rather brief overview of selected Python libraries for working withweb technologies and protocols. Several topics, like the handling of email functionalitywith Python, are not touched upon.",
    "The File Transfer Protocol(FTP) is, as the name suggests, a protocol to transfer filesover the Web.1Python provides a dedicated library to work with FTP called ftplib:In[1]:importftplibimportnumpyasnpIn what follows, we will connect to an FTP server, log in, transfer a file to the server,transfer it back to the local machine, and delete the file on the server. First, the connection:In[2]:ftp=ftplib.FTP('quant-platform.com')Not every FTP server is password protected, but this one is:In[3]:ftp.login(user='python',passwd='python')Out[3]: '230 Login successful.'To have a file that we can transfer, we generate a NumPyndarray object with some randomdata and save it to disk:In[4]:np.save('./data/array',np.random.standard_normal((100,100)))For the FTP file transfer to follow, we have to open the file for reading:In[5]:f=open('./data/array.npy','r')This open file can now be written, choosing here binary transfer, by the STORcommandin combination with the target filename:In[6]:ftp.storbinary('STOR array.npy',f)Out[6]: '226 Transfer complete.'Let us have a look at the directory of the FTP server. Indeed, the file was transferred:In[7]:ftp.retrlines('LIST')Out[7]: -rw-------    1 1001     1001        80080 Sep 29 11:05 array.npy        '226 Directory send OK.'The other way around is pretty similar. To retrieve a distant file and to save it to disk,we need to open a new file, this time in write mode:In[8]:f=open('./data/array_ftp.npy','wb').writeAgain, we choose binary transfer, and we use the RETR command for retrieving the filefrom the FTP server:In[9]:ftp.retrbinary('RETR array.npy',f)",
    "Another important protocol, if not the most important one on the Web, is the HyperTextTransfer Protocol (HTTP).2This protocol is used whenever a (HTML-based) web pageis displayed in the browser. The Python library to work with HTTP is called httplib:In[20]:importhttplibAs with FTP, we first need a connection to the HTTP server:In[21]:http=httplib.HTTPConnection('hilpisch.com')Once the connection is established, we can send requests, for example asking for theindex.htm page (file):In[22]:http.request('GET','/index.htm')To test whether this was successful, use the getresponse method:In[23]:resp=http.getresponse()The returned object provides status information. Fortunately, our request wassuccessful:In[24]:resp.status,resp.reasonOut[24]: (200, 'OK')Equipped with the response object, we can now read the content as follows:In[25]:content=resp.read()content[:100]# first 100 characters of the fileOut[25]: '%3C!doctype html%3E%5Cn%3Chtml lang=%22en%22%3E%5Cn%5Cn%5Ct%3Chead%3E%5Cn%5Ct%5Ct%3Cmeta charset=%22utf-         8%22%3E%5Cn%5Cn%5Ct%5Ct%3Ctitle%3EDr. Yves J. Hilpisch %5Cxe2%5Cx80'Once you have the content of a particular web page, there are many potential use cases.You might want to look up certain information, for example. You might know that youcan find the email address on the page by looking for E(in this very particular case).Since content is a string object, you can apply the find method to look for E:3In[26]:index=content.find(' E ')indexOut[26]: 2071Equipped with the index value for the information you are looking for, you can inspectthe subsequent characters of the object:",
    "There is another Python library that supports the use of differentweb protocols. It iscalled urllib. There is also a related library called urllib2. Both libraries are designedto work with arbitrary web resources, in the spirit of the %E2%80%9Cuniform%E2%80%9D in URL(uniformresource locator).4 A standard use case, for example, is to retrieve files, like CSVdatafiles, via the Web. Begin by importing urllib:In[29]:importurllibThe application of the library's functions resembles that of both ftplib and httplib.Of course, we need a URLrepresenting the web resource of interest (HTTP or FTP server,in general). For this example, we use the URLof Yahoo! Finance to retrieve stock priceinformation in CSV format:In[30]:url='http://ichart.finance.yahoo.com/table.csv%3Fg=d%26ignore=.csv'url%2B='%26s=YHOO%26a=01%26b=1%26c=2014%26d=02%26e=6%26f=2014'Next, one has to establish a connection to the resource:In[31]:connect=urllib.urlopen(url)With the connection established, read out the content by calling the readmethod onthe connection object:In[32]:data=connect.read()The result in this case is historical stock price information for Yahoo! itself:In[33]:printdataOut[33]: Date,Open,High,Low,Close,Volume,Adj Close         2014-03-06,39.60,39.98,39.50,39.66,10626700,39.66         2014-03-05,39.83,40.15,39.19,39.50,12536800,39.50         2014-03-04,38.76,39.79,38.68,39.63,16139400,39.63         2014-03-03,37.65,38.66,37.43,38.25,14714700,38.25         2014-02-28,38.55,39.38,38.22,38.67,16957100,38.67         2014-02-27,37.80,38.48,37.74,38.47,15489400,38.47         2014-02-26,37.35,38.10,37.34,37.62,15778900,37.62         2014-02-25,37.48,37.58,37.02,37.26,9756900,37.26         2014-02-24,37.23,37.71,36.82,37.42,15738900,37.42         2014-02-21,37.90,37.96,37.22,37.29,12351900,37.29",
    "Chapter 5 introduces matplotlib, the most popular plotting library for Python. However, as powerful as it might be for 2D and 3D plotting, its strength lies in static plotting.In fact, matplotlibis also able to generate interactive plots, e.g., with sliders for variables. But it is safe to say that this is not one of its strengths.5This section starts with generating static plots, then proceeds to interactiveplots tofinally arrive at real-time plotting.",
    "First, a brief benchmark example using the pandas library based on a financial timeseries from the Yahoo! Finance API, as used in the previous section:In[44]:importnumpyasnpimportpandasaspd%25matplotlibinlineAs shown in Chapter 6, using pandas makes data retrieval from the Web in general quiteconvenient. We do not even have to use additional libraries, such as urllib-almosteverything happens under the hood. The following retrieves historical stock pricequotes for Microsoft Inc. and stores the data in a DataFrame object:In[45]:url='http://ichart.yahoo.com/table.csv%3Fs=MSFT%26a=0%26b=1%26c=2009'data=pd.read_csv(url,parse_dates=['Date'])pandas accepts column names as parameter values for the xand ycoordinates. Theresult is shown in Figure 14-1:In[46]:data.plot(x='Date',y='Close')",
    "The next step is to add interactivity to the web-based plot. Available interactivity elements (%E2%80%9Ctools%E2%80%9D) include:panSupports panning of the plot (like panning with a movie camera)%3B i.e., moving theplot (including x and y coordinates) relative to the fixed plotting frame",
    "The previous subsection shows how easy it is to generate interactive, web-based plotswith Bokeh. However, Bokeh shines when it comes to real-time visualization of, forexample, high-frequency financial data. Therefore, this subsection contains examplesfor two different real-time APIs, one for FX (foreign exchange) data in JSON(JavaScriptObject Notation) format and one for intraday tick data for stock prices delivered in",
    "Our first example is based on a JSON API for, among others, FX rates. Some importsfirst:In[51]:importtimeimportpandasaspdimportdatetimeasdtimportrequestsThe API we use is from OANDA, an FX online broker. This broker offers an API sandboxthat provides random/dummy data that resembles real exchange rates. Our example isbased on the EUR%E2%80%93USD exchange rate (cf. the API guide):In[52]:url='http://api-sandbox.oanda.com/v1/prices%3Finstruments=%25s'# real-time FX (dummy!) data from JSON APITo connect to the API we use the requestslibrary whose aim is to improve the interfacefor %E2%80%9Chumans%E2%80%9D when interacting with web resources:In[53]:instrument='EUR_USD'api=requests.get(url%25instrument)With the open connection, data in JSON format is simply read by calling the methodjson on the connection object:In[54]:data=api.json()dataOut[54]: %7Bu'prices': [%7Bu'ask': 1.25829,            u'bid': 1.2582,            u'instrument': u'EUR_USD',            u'time': u'2014-09-29T06:14:34.749878Z'%7D]%7DUnfortunately, the data is not yet completely in the format we would like it to have.Therefore, we transform it a bit. The following code takes only the first element of thelist object stored under the key %E2%80%9Cprices.%E2%80%9D The resulting object is a standard dictobject:In[55]:data=data['prices'][0]dataOut[55]: %7Bu'ask': 1.25829,          u'bid': 1.2582,          u'instrument': u'EUR_USD',          u'time': u'2014-09-29T06:14:34.749878Z'%7DSince we collect such small data sets at a high frequency, we use a DataFrame object tostore all the data. The following code initializes an appropriate DataFrame object:In[56]:ticks=pd.DataFrame(%7B'bid':data['bid'],'ask':data['ask'],",
    "We start by generating the needed directories. tradechatshall be the main directory.In addition, at a minimum, we need the two subdirectories static and templates (byFlask convention):%24 mkdir tradechat%24 mkdir tradechat/static%24 mkdir tradechat/templatesTo store data-both for registered users and for comments made in the chat room-weuse SQLite3 (cf. http://www.sqlite.org and http://docs.python.org/2/library/sqlite3.html) as a database. Two different tables are needed that can be generated by theSQL schema presented in Example 14-1, the details of which we do not discuss here. Youshould store this under the filename tables.sqlin the main directory of the application, tradechat.Example 14-1. SQL schema to generate tables in SQLite3droptableifexistscomments%3Bcreatetablecomments(idintegerprimarykeyautoincrement,commenttextnotnull,usertextnotnull,timetextnotnull)%3Bdroptableifexistsusers%3B",
    "The SQLschema is a main input for the Python/Flaskapplication to follow. We will gothrough the single elements step by step to finally arrive at the complete Python scriptto be stored under tradechat.py in the main directory, tradechat.",
    "Basically, templating with Flask(Jinja2) works similarly to simple string replacementsin Python: you have a basic stringindicating where to replace what and some data tobe inserted into the string object. Consider the following examples:In[77]:'%25d, %25d, %25d'%25(1,2,3)Out[77]: '1, 2, 3'In[78]:'%7B%7D, %7B%7D, %7B%7D'.format(1,2,3)Out[78]: '1, 2, 3'In[79]:'%7B%7D, %7B%7D, %7B%7D'.format(*'123')Out[79]: '1, 2, 3'Templating to generate HTMLpages works pretty similarly. The major difference is thatthe string object %E2%80%9Cresembles%E2%80%9D an HTML document (or a part thereof) and has commandsfor replacements and also, for example, ways of controlling the flow when renderingthe template (e.g., the for loop). Missing information is added during the renderingprocedure, as we added the integers to the string object in the previous examples.Consider now the following stringobject, containing partly standard HTML code andsome template-specific code:In[80]:templ='''%3C!doctype html%3E           Just print out %3Cb%3Enumbers%3C/b%3E provided to the template.           %3Cbr%3E%3Cbr%3E           %7B%25 for number in numbers %25%7D             %7B%7B number %7D%7D           %7B%25 endfor %25%7D         '''So far, this is a stringobject only. We have to generate a Jinja2Template object outof it before proceeding:In[81]:fromjinja2importTemplateIn[82]:t=Template(templ)This Template object has a method called render to make valid HTML code out of thetemplate and some input values-in this case, some numbers via the parameter numbers:",
    "Today's standard when it comes to the styling of web pages and web-based applicationsis CSS (Cascading Style Sheets). If you take a closer look at the single templates, youwill find in many places parameterizations like class=commentsor class=add-comment. Without a corresponding CSS file, these parameterizations are essentiallymeaningless.Therefore, let us have a look at the file style.css, stored in the (sub)directory staticand shown in Example 14-7. Here you find the aforementioned parameters (comments, add-comment) again. You also find references to standard HTMLtags, like h1 forthe highest-ranking header. All information provided after a custom class name, likecomments, or a standard tag, like h1, defines or changes certain style elements (e.g., fonttype and/or size) of the relevant object.This style information is the final ingredient defining the look of the Tradechat application and explaining why, for example, the %E2%80%9CTradechat%E2%80%9D heading is displayed in blue(namely, due to the line a, h1, h2 %7B color: #0066cc%3B %7D).",
    "The last topic in this chapter-and a very interesting and important one-is web services. Web services provide a simple and efficient means to access server-based functionality via web protocols. For example, one of the web services with the highest trafficis the Google search functionality. We are used to visiting http://www.google.comandtyping some words of interest into the search/text input field provided on the website.However, what happens after you press the Return key or push the Search button is thatthe page translates all the information it has (from the search field and maybe yourpersonal preferences) into a more or less complex URL.Such a URL could, for example, take on the form http://www.google.de/search%3Fnum=5%26q=yves%2Bpython. When you click this link or copy it into your web browser,Google Search returns those five search results (num=5) that the engine considers thebest matches given the words provided (q=Yves%2BPython). Your web browser then displays something similar to Figure 14-11.Using web services, any kind of data- and transaction-oriented financial service can beprovided via web technologies. For instance, Yahoo! Finance and Google Finance offerhistorical stock price information via such a web service approach. More complex services such as derivatives pricing and risk analytics are also available via such services (forexample, the web-based analytics solution DEXISION%3B cf. http://derivatives-analytics.com). The following example illustrates the implementation of such a servicein the context of option pricing.",
    "In this section, we are going to implement a web service that allows us to value volatilityoptions (e.g., on a volatility index). The model we use is the one of Gruenbichler andLongstaff (1996). They model the volatility process (e.g., the process of a volatility index)in direct fashion by a square-root diffusion, provided in Equation 14-1. This process isknown to exhibit convenient features for volatility modeling, like positivity and meanreversion.10",
    "Nowadays, web technologies are an integral part of almost any application architecture.They are not only beneficial for communicating with the outside world and providingsimple to sophisticated web services to external entities, but also within (financial)organizations.This chapter first illustrates some basic techniques with regard to the most commoncommunication protocols (mainly FTP and HTTP). It also shows how to implement interactive web plotting, how to interface in real time with web-based financial data APIs(e.g., JSON-based) and how to visualize such high frequency data in real time withBokeh. These basic tools and techniques are helpful in almost any context.However, the Pythonecosystem also provides a number of powerful, high level frameworks to develop even complex web applications in rapid fashion. We use Flask, aframework which has gained some popularity recently, to implement a simple chat roomfor traders with simple user administration (registration and login). All elements of atypical web application-core functionality in Python, templating with Jinja2, andstyling with CSS-are illustrated.",
    "The following web resources are helpful with regard to the topics covered in this chapter:%E2%80%A2The Pythondocumentation should be a starting point for the basic tools and techniques shown in this chapter: http://docs.python.org%3B see also this overview page:http://docs.python.org/2/howto/webservers.html.%E2%80%A2You should consult the home page of Bokehfor more on this webfocused plottinglibrary: http://bokeh.pydata.org.%E2%80%A2For more on Flask, start with the home page of the framework: http://flask.pocoo.org%3B also, download the PDF documentation: https://media.readthedocs.org/pdf/flask/latest/flask.pdf.%E2%80%A2Apart from the Python documentation itself, consult the home page of the Werkzeuglibrary for more on web services: http://werkzeug.pocoo.org.For a Flask reference in book form, see the following:%E2%80%A2Grinberg, Miguel (2014): Flask Web Development-Developing Web Applicationswith Python. O'Reilly, Sebastopol, CA.Finally, here is the research paper about the valuation of volatility options:%E2%80%A2Gruenbichler, Andreas and Francis Longstaff (1996): %E2%80%9CValuing Futures and Optionson Volatility.%E2%80%9D Journal of Banking and Finance, Vol. 20, pp. 985%E2%80%931001.",
    "Consider a simple economy at the dates today and tomorrow with a risky asset, a %E2%80%9Cstock,%E2%80%9Dand a riskless asset, a %E2%80%9Cbond.%E2%80%9D The bond costs 10 USD today and pays off 10 USD tomorrow (zero interest rates). The stock costs 10 USD today and, with a probability of60%25 and 40%25, respectively, pays off 20 USD and 0 USD tomorrow. The riskless returnof the bond is 0. The expected return of the stock is 0.6%C2%B720%2B0.4%C2%B7010%E2%88%921=0.2, or 20%25. This isthe risk premium the stock pays for its riskiness.Consider now a call option with strike price of 15 USD. What is the fair value of sucha contingent claim that pays 5 USD with 60%25 probability and 0 USD otherwise%3F We cantake the expectation, for example, and discount the resulting value back (here with zerointerest rates). This approach yields a value of 0.6 %C2%B7 5 = 3 USD, since the option pays 5USD in the case where the stock price moves up to 20 USD and 0 USD otherwise.However, there is another approach that has been successfully applied to option pricingproblems like this: replication of the option's payoff through a portfolio of traded securities. It is easily verified that buying 0.25 of the stock perfectly replicates the option'spayoff (in the 60%25 case we then have 0.25 %C2%B7 20 = 5 USD). A quarter of the stock onlycosts 2.5 USD and not 3 USD. Taking expectations under the real-world probabilitymeasure overvalues the option.Why is this case%3F The real-world measure implies a risk premium of 20%25 for the stocksince the risk involved in the stock (gaining 100%25 or losing 100%25) is %E2%80%9Creal%E2%80%9D in the sensethat it cannot be diversified or hedged away. On the other hand, there is a portfolioavailable that replicates the option's payoff without any risk. This also implies thatsomeone writing (selling) such an option can completely hedge away any risk.2 Such aperfectly hedged portfolio of an option and a hedge position must yield the riskless ratein order to avoid arbitrage opportunities (i.e., the opportunity to make some moneyout of no money with a positive probability).Can we save the approach of taking expectations to value the call option%3F Yes, we can.We %E2%80%9Conly%E2%80%9D have to change the probability in such a way that the risky asset, the stock,drifts with the riskless short rate of zero. Obviously, a (martingale) measure giving equalmass of 50%25 to both scenarios accomplishes this%3B the calculation is 0.5%C2%B720%2B0.5%C2%B7010%E2%88%921=0.Now, taking expectations of the option's payoff under the new martingale measure yieldsthe correct (arbitrage-free) fair value: 0.5 %C2%B7 5 %2B 0.5 %C2%B7 0 = 2.5 USD.",
    "The beauty of this approach is that it carries over to even the most complex economieswith, for example, continuous time modeling (i.e., a continuum of points in time toconsider), large numbers of risky assets, complex derivative payoffs, etc.Therefore, consider a general market model in discrete time:3A general market model%E2%84%B3 in discrete time is a collection of:%E2%80%A2 A finite state space %ED%9B%BA%E2%80%A2 A filtration %ED%90%80%E2%80%A2 A strictly positive probability measure P defined on %E2%84%98(%ED%9B%BA)%E2%80%A2 A terminal date T%E2%88%88%E2%84%95, T %3C %E2%88%9E%E2%80%A2 A set %ED%90%80%E2%89%A1Stkt%E2%88%880,...,T:k%E2%88%880,...,K of K %2B 1 strictly positive security price processesWe write %E2%84%B3 = %7B(%ED%9B%BA,%E2%84%98(%ED%9B%BA),%ED%90%80,P),T,%ED%90%80%7D.Based on such a general market model, we can formulate the Fundamental Theorem ofAsset Pricing as follows:4Consider the general market model %E2%84%B3. According to the Fundamental Theorem of AssetPricing, the following three statements are equivalent:%E2%80%A2 There are no arbitrage opportunities in the market model %E2%84%B3.%E2%80%A2 The set %E2%84%9A of P-equivalent martingale measures is nonempty.%E2%80%A2 The set %E2%84%99 of consistent linear price systems is nonempty.When it comes to valuation and pricing of contingent claims (i.e., options, derivatives,futures, forwards, swaps, etc.), the importance of the theorem is illustrated by the following corollary:If the market model %E2%84%B3 is arbitrage-free, then there exists a unique priceV0 associatedwith any attainable (i.e., replicable) contingent claim (option, derivative, etc.) VT. It satisfies %E2%88%80Q%E2%88%88%E2%84%9A:V0=%ED%90%800Qe%E2%88%92rTVT, where e%E2%80%93rTis the relevant risk-neutral discount factor fora constant short rate r.This result illustrates the importance of the theorem, and shows that our simple reasoning from the introductory above indeed carries over to the general market model.Due to the role of the martingale measure, this approach to valuation is also often calledthe martingale approach, or-since under the martingale measure all risky assets driftwith the riskless short rate-the risk-neutral valuation approach. The second term",
    "We focus on the simplest case for discounting by the short rate%3B namely, the case wherethe short rate is constant through time. Many option pricing models, like the ones ofBlack-Scholes-Merton (1973), Merton (1976), and Cox-Ross-Rubinstein (1979), makethis assumption.6 We assume continuous discounting, as is usual for option pricingapplications. In such a case, the general discount factor as of today, given a future datetand a constant short rate of r, is then given by D0(t) = e%E2%80%93rt. Of course, for the end of theeconomy we have the special case D0(T) = e%E2%80%93rT. Note that here both t and T are in yearfractions.The discount factors can also be interpreted as the value of a unit zero-coupon bond(ZCB) as of today, maturing at tand T, respectively.7Given two dates t%E2%89%A5s%E2%89%A5 0, thediscount factor relevant for discounting from t to sis then given by the equation Ds(t)= D0(t) / D0(s) = e%E2%80%93rt / e%E2%80%93rs = e%E2%80%93rt %C2%B7 ers = e%E2%80%93r(t%E2%80%93s).Example 15-2 presents a Python class that translates all these considerations into Pythoncode.8Example 15-2. Class for risk-neutral discounting with constant short rate## DX Library Frame# constant_short_rate.py#fromget_year_deltasimport*classconstant_short_rate(object):''' Class for constant short rate discounting.",
    "Market environmentis %E2%80%9Cjust%E2%80%9D a name for a collection of other data and Python objects.However, it is rather convenient to work with this abstraction since it simplifies a number of operations and also allows for a consistent modeling of recurring aspects.9Amarket environment mainly consists of three dictionaries to store the following typesof data and Python objects:ConstantsThese can be, for example, model parameters or option maturity dates.ListsThese are sequences of objects in general, like a list object of objects modeling(risky) securities.CurvesThese are objects for discounting%3B for example, like an instance of the constant_short_rate class.Example 15-3 presents the market_environment class. Refer to Chapter 4 for a refresheron the handling of dict objects.Example 15-3. Class for modeling a market environment with constants, lists, andcurves## DX Library Frame# market_environment.py#classmarket_environment(object):''' Class to model a market environment relevant for valuation.    Attributes    ==========    name: string",
    "This chapter provides the framework for the larger project of building a Python libraryto value options and other derivatives by Monte Carlo simulation. The chapter introduces the Fundamental Theorem of Asset Pricing, illustrating it by a rather simple numerical example. Important results in this regard are provided for a general marketmodel in discrete time.The chapter also develops a Python class for risk-neutral discounting purposes to makenumerical use of the machinery of the Fundamental Theorem of Asset Pricing. Basedon a list of either Pythondatetime objects or floats representing year fractions, instances of the class constant_short_rate provide the respective discount factors(present values of unit zero-coupon bonds).The chapter concludes with the rather generic market_environmentclass, which allowsfor the collection of relevant data and Pythonobjects for modeling, simulation, valuation, and other purposes.To simplify future imports we will use a wrapper module called dx_frame.py, as presented in Example 15-4.Example 15-4. Wrapper module for framework components## DX Library Frame# dx_frame.py#importdatetimeasdtfromget_year_deltasimportget_year_deltasfromconstant_short_rateimportconstant_short_ratefrommarket_environmentimportmarket_environmentA single import statement like the following then makes all framework componentsavailable in a single step:fromdx_frameimport*",
    "Useful references in book form for the topics covered in this chapter are:%E2%80%A2Delbaen, Freddy and Walter Schachermayer (2004): The Mathematics of Arbitrage. Springer Verlag, Berlin, Heidelberg.%E2%80%A2Fletcher, Shayne and Christopher Gardner (2009): Financial Modelling in Python.John Wiley %26 Sons, Chichester, England.%E2%80%A2Hilpisch, Yves (2015): Derivatives Analytics with Python. Wiley Finance, Chichester, England. http://derivatives-analytics-with-python.com.%E2%80%A2Williams, David (1991): Probability with Martingales. Cambridge University Press,Cambridge, England.For the original research papers defining the models cited in this chapter, refer to the%E2%80%9CFurther Reading%E2%80%9D sections in subsequent chapters.",
    "Example 16-3now presents the specialized class for the GBM model. We present it inits entirety first and highlight selected aspects afterward.Example 16-3. Simulation class for geometric Brownian motion## DX Library Simulation# geometric_brownian_motion.py#importnumpyasnpfromsn_random_numbersimportsn_random_numbersfromsimulation_classimportsimulation_classclassgeometric_brownian_motion(simulation_class):''' Class to generate simulated paths based on    the Black-Scholes-Merton geometric Brownian motion model.    Attributes    ==========    name : string        name of the object    mar_env : instance of market_environment        market environment data for simulation    corr : Boolean        True if correlated with other model simulation object    Methods    =======    update :        updates parameters    generate_paths :        returns Monte Carlo paths given the market environment    '''def__init__(self,name,mar_env,corr=False):super(geometric_brownian_motion,self).__init__(name,mar_env,corr)defupdate(self,initial_value=None,volatility=None,final_date=None):ifinitial_valueisnotNone:self.initial_value=initial_valueifvolatilityisnotNone:",
    "The following interactive IPythonsession illustrates the use of the geometric_brownian_motion class. First, we have to generate a market_environmentobject with allmandatory elements:In[1]:fromdximport*In[2]:me_gbm=market_environment('me_gbm',dt.datetime(2015,1,1))In[3]:me_gbm.add_constant('initial_value',36.)me_gbm.add_constant('volatility',0.2)me_gbm.add_constant('final_date',dt.datetime(2015,12,31))me_gbm.add_constant('currency','EUR')me_gbm.add_constant('frequency','M')# monthly frequency (respective month end)me_gbm.add_constant('paths',10000)In[4]:csr=constant_short_rate('csr',0.05)In[5]:me_gbm.add_curve('discount_curve',csr)Second, we instantiate a model simulation object:In[6]:fromdx_simulationimport*In[7]:gbm=geometric_brownian_motion('gbm',me_gbm)Third, we can work with the object. For example, let us generate and inspect thetime_grid. You will notice that we have 13 datetime objects in the time_gridarrayobject (all the month ends in the relevant year, plus the pricing_date):In[8]:gbm.generate_time_grid()In[9]:gbm.time_gridOut[9]: array([datetime.datetime(2015, 1, 1, 0, 0),               datetime.datetime(2015, 1, 31, 0, 0),               datetime.datetime(2015, 2, 28, 0, 0),               datetime.datetime(2015, 3, 31, 0, 0),               datetime.datetime(2015, 4, 30, 0, 0),               datetime.datetime(2015, 5, 31, 0, 0),               datetime.datetime(2015, 6, 30, 0, 0),               datetime.datetime(2015, 7, 31, 0, 0),               datetime.datetime(2015, 8, 31, 0, 0),               datetime.datetime(2015, 9, 30, 0, 0),               datetime.datetime(2015, 10, 31, 0, 0),               datetime.datetime(2015, 11, 30, 0, 0),               datetime.datetime(2015, 12, 31, 0, 0)], dtype=object)Next, we might ask for the simulated instrument values:",
    "Equipped with the background knowledge from the geometric_brownian_motionclass, it is now straightforward to implement a class for the jump diffusion model described by Merton (1976). Recall the stochastic differential equation of the jump diffusion, as shown in Equation 16-3 (see also Equation 10-8 in Chapter 10, in particular forthe meaning of the parameters and variables).Equation 16-3. Stochastic differential equation for Merton jump diffusion modeldSt = (r %E2%80%93 rJ)Stdt %2B %ED%9C%8EStdZt %2B JtStdNtAn Euler discretization for simulation purposes is presented in Equation 16-4 (see alsoEquation 10-9 in Chapter 10 and the more detailed explanations given there).Equation 16-4. Euler discretization for Merton jump diffusion modelStm%2B1=Stmexpr%E2%88%92rJ%E2%88%9212%CF%832tm%2B1%E2%88%92tm%2B%CF%83tm%2B1%E2%88%92tmzt1%2Be%CE%BCJ%2B%CE%B4zt2%E2%88%921yt0%E2%89%A4tm%3Ctm%2B1%E2%89%A4T",
    "Example 16-4 presents the Python code for the jump_diffusion simulation class. Thisclass should by now contain no surprises. Of course, the model is different, but thedesign and the methods are essentially the same.",
    "In what follows, we again illustrate the use of the simulation class jump_diffusioninteractively. We make use of the market_environment object defined for the GBMobject in the previous section:In[15]:me_jd=market_environment('me_jd',dt.datetime(2015,1,1))In[16]:# add jump diffusion specific parametersme_jd.add_constant('lambda',0.3)me_jd.add_constant('mu',-0.75)me_jd.add_constant('delta',0.1)To this environment, we add the complete environment of the GBM simulation class,which completes the input needed:In[17]:me_jd.add_environment(me_gbm)Based on this market_environment object, we can instantiate the simulation class forthe jump diffusion:In[18]:fromjump_diffusionimportjump_diffusionIn[19]:jd=jump_diffusion('jd',me_jd)Due to the modeling approach we have implemented, the generation of instrumentvalues is now formally the same. The method call in this case is a bit slower, however,since we need to simulate more numerical values due to the jump component:",
    "The third stochastic process to be simulated is the square-root diffusion as used by Cox,Ingersoll, and Ross (1985) to model stochastic short rates. Equation 16-5shows thestochastic differential equation of the process (see also Equation 10-4 in Chapter 10 forfurther details).",
    "Example 16-5 presents the Python code for the square_root_diffusionsimulationclass. Apart from, of course, a different model and discretization scheme, the class doesnot contain anything new compared to the other two specialized classes.Example 16-5. Simulation class for square-root diffusion## DX Library Simulation# square_root_diffusion.py#importnumpyasnpfromsn_random_numbersimportsn_random_numbersfromsimulation_classimportsimulation_classclasssquare_root_diffusion(simulation_class):''' Class to generate simulated paths based on    the Cox-Ingersoll-Ross (1985) square-root diffusion model.    Attributes    ==========    name : string        name of the object    mar_env : instance of market_environment        market environment data for simulation    corr : Boolean        True if correlated with other model object    Methods    =======",
    "A rather brief use case illustrates the use of the simulation class. As usual, we need amarket environment, for example to model a volatility (index) process:In[35]:me_srd=market_environment('me_srd',dt.datetime(2015,1,1))In[36]:me_srd.add_constant('initial_value',.25)me_srd.add_constant('volatility',0.05)me_srd.add_constant('final_date',dt.datetime(2015,12,31))me_srd.add_constant('currency','EUR')me_srd.add_constant('frequency','W')me_srd.add_constant('paths',10000)Two components of the market environment are specific to the class:In[37]:# specific to simualation classme_srd.add_constant('kappa',4.0)me_srd.add_constant('theta',0.2)Although we do not need it here to implement the simulation, the generic simulationclass requires a discounting object. This requirement can be justified from a risk-neutralvaluation perspective, which is the overarching goal of the whole DX analytics library:In[38]:# required but not needed for the classme_srd.add_curve('discount_curve',constant_short_rate('r',0.0))In[39]:fromsquare_root_diffusionimportsquare_root_diffusionIn[40]:srd=square_root_diffusion('srd',me_srd)As before, we get simulation paths, given the market_environmentobject as input, bycalling the get_instrument_values method:In[41]:srd_paths=srd.get_instrument_values()[:,:10]",
    "This chapter develops all the tools and classes needed for the simulation of the threestochastic processes of interest: geometric Brownian motions, jump diffusions, andsquare-root diffusions. The chapter presents a function to conveniently generate standard normally distributed random numbers. It then proceeds by introducing a genericmodel simulation class. Based on this foundation, the chapter introduces three specialized simulation classes and presents use cases for these classes.To simplify future imports, we can again use a wrapper module called dx_simulation.py, as presented in Example 16-6.Example 16-6. Wrapper module for simulation components## DX Library Simulation# dx_simulation.py#importnumpyasnpimportpandasaspdfromdx_frameimport*fromsn_random_numbersimportsn_random_numbers",
    "Useful references in book form for the topics covered in this chapter are:%E2%80%A2Glasserman, Paul (2004): Monte Carlo Methods in Financial Engineering. Springer,New York.%E2%80%A2Hilpisch, Yves (2015): Derivatives Analytics with Python. Wiley Finance, Chichester, England. http://derivatives-analytics-with-python.com.Original papers cited in this chapter are:",
    "The first case to which we want to specialize the generic valuation class is Europeanexercise. To this end, consider the following simplified recipe to generate a Monte Carloestimator for an option value:1.Simulate the relevant underlying risk factor S under the risk-neutral measure Itimesto come up with as many simulated values of the underlying at the maturity of theoption T-i.e., STi,i%E2%88%881,2,...,I",
    "Example 17-2 shows the class implementing the present_value method based on thisrecipe. In addition, it contains the method generate_payoffto generate the simulatedpaths and the payoff of the option given the simulated paths. This, of course, builds thevery basis for the Monte Carlo estimator.Example 17-2. Valuation class for European exercise## DX Library Valuation# valuation_mcs_european.py#importnumpyasnpfromvaluation_classimportvaluation_classclassvaluation_mcs_european(valuation_class):''' Class to value European options with arbitrary payoff    by single-factor Monte Carlo simulation.    Methods    =======    generate_payoff :        returns payoffs given the paths and the payoff function    present_value :        returns present value (Monte Carlo estimator)    '''defgenerate_payoff(self,fixed_seed=False):'''        Parameters        ==========        fixed_seed : Boolean            use same/fixed seed for valuation        '''try:# strike defined%3Fstrike=self.strikeexcept:passpaths=self.underlying.get_instrument_values(fixed_seed=fixed_seed)time_grid=self.underlying.time_gridtry:",
    "The application of the valuation class valuation_mcs_european is best illustrated by aspecific use case. However, before a valuation class can be instantiated, we need a simulation object-i.e., an underlying for the option to be valued. From Chapter 16, we usethe geometric_brownian_motion class to model the underlying. We also use the example parameterization of the respective use case there:In[1]:fromdximport*In[2]:me_gbm=market_environment('me_gbm',dt.datetime(2015,1,1))In[3]:me_gbm.add_constant('initial_value',36.)me_gbm.add_constant('volatility',0.2)me_gbm.add_constant('final_date',dt.datetime(2015,12,31))me_gbm.add_constant('currency','EUR')me_gbm.add_constant('frequency','M')me_gbm.add_constant('paths',10000)In[4]:csr=constant_short_rate('csr',0.06)In[5]:me_gbm.add_curve('discount_curve',csr)In[6]:gbm=geometric_brownian_motion('gbm',me_gbm)In addition to a simulation object, we need to provide a market environment for theoption itself. It has to contain at least a maturity and a currency. Optionally, we canprovide a strike:In[7]:me_call=market_environment('me_call',me_gbm.pricing_date)In[8]:me_call.add_constant('strike',40.)me_call.add_constant('maturity',dt.datetime(2015,12,31))me_call.add_constant('currency','EUR')A central element, of course, is the payoff function, provided here as a stringobjectcontaining Python code that the eval function can evaluate. We want to define a European calloption. Such an option has a payoff of hT = max(ST %E2%80%93 K,0), with ST being thevalue of the underlying at maturity and K being the strike price of the option. In Pythonand NumPy-i.e., with vectorized storage of all simulated values-this takes on the following form:In[9]:payoff_func='np.maximum(maturity_value - strike, 0)'We can now put all the ingredients together to instantiate the valuation_mcs_europeanclass:In[10]:fromvaluation_mcs_europeanimportvaluation_mcs_european",
    "The valuation of options with American exercise-or Bermudan exercise, to this end2-is much more involved than with European exercise. Therefore, we have to introducea bit more valuation theory first before proceeding to the valuation class.",
    "Example 17-4 presents the class for the valuation of options and derivatives with American exercise. There is one noteworthy step in the implementation of the LSM algorithmin the present_value method (which is also commented on inline): the optimal decisionstep. Here, it is important that, based on the decision that is made, the LSM algorithm",
    "As has become by now the means of choice, a use case shall illustrate how to work withthe valuation_mcs_americanclass. The use case replicates all American option valuesas presented in Table 1 of the seminal paper by Longstaff and Schwartz (2001). Theunderlying is the same as before, a geometric_brownian_motionobject. The startingparameterization for the underlying is as follows:In[22]:fromdx_simulationimport*In[23]:me_gbm=market_environment('me_gbm',dt.datetime(2015,1,1))",
    "This chapter is about the numerical valuation of both European and American optionsbased on Monte Carlo simulation. The chapter introduces a generic valuation class,called valuation_class. This class provides methods, for example, to estimate the mostimportant Greeks (Delta, Vega) for both types of options, independent of the simulationobject (risk factor/stochastic process) used for the valuation.Based on the generic valuation class, the chapter presents two specialized classes, valuation_mcs_european and valuation_mcs_american. The class for the valuation of European options is mainly a straightforward implementation of the risk-neutral valuationapproach presented in Chapter 15in combination with the numerical estimation of anexpectation term (i.e., an integral by Monte Carlo simulation, as discussed in Chapter 9).The class for the valuation of American options needs a certain kind of regression-basedvaluation algorithm. This is due to the fact that for American options an optimal exercisepolicy has to be derived for a valuation. This is theoretically and numerically a bit moreinvolved. However, the respective present_value method of the class is still concise.The approach taken with the DX derivatives analytics library proves to be beneficial.Without too much effort we are able to value a pretty large class of options with thefollowing features:%E2%80%A2Single risk factor options%E2%80%A2European or American exercise",
    "In principle, a derivatives position is nothing more than a combination of a valuationobject and a quantity for the instrument modeled.",
    "Example 18-1 presents the class to model a derivatives position. It is mainly a containerfor other data and objects. In addition, it provides a get_info method, printing the dataand object information stored in an instance of the class.Example 18-1. A simple class to model a derivatives position## DX Library Portfolio# derivatives_position.py#classderivatives_position(object):''' Class to model a derivatives position.    Attributes    ==========    name : string        name of the object    quantity : float",
    "The following interactive session illustrates the use of the class. However, we need tofirst define a simulation object-but not in full%3B only the most important, object-specificinformation is needed. Here, we basically stick to the numerical examples from theprevious two chapters:In[1]:fromdximport*For the definition of the derivatives position, we do not need a %E2%80%9Cfull%E2%80%9D market_environment object. Missing information is provided later (during the portfolio valuation),when the simulation object is instantiated:In[2]:me_gbm=market_environment('me_gbm',dt.datetime(2015,1,1))In[3]:me_gbm.add_constant('initial_value',36.)me_gbm.add_constant('volatility',0.2)me_gbm.add_constant('currency','EUR')However, for the portfolio valuation, one additional constant is needed-namely, forthe model to be used. This will become clear in the subsequent section:In[4]:me_gbm.add_constant('model','gbm')With the simulation object available, we can proceed to define a derivatives position asfollows:In[5]:fromderivatives_positionimportderivatives_positionIn[6]:me_am_put=market_environment('me_am_put',dt.datetime(2015,1,1))In[7]:me_am_put.add_constant('maturity',dt.datetime(2015,12,31))me_am_put.add_constant('strike',40.)me_am_put.add_constant('currency','EUR')",
    "From a portfolio perspective, a %E2%80%9Crelevant market%E2%80%9D is mainly composed of the relevantrisk factors (underlyings) and their correlations, as well as the derivatives and derivativespositions, respectively, to be valued. Theoretically, we are now dealing with a generalmarket model %E2%84%B3 as defined in Chapter 15, and applying the Fundamental Theorem ofAsset Pricing (with its corollaries) to it.1",
    "This chapter addresses the valuation and risk management of a portfolio of multiplederivatives positions dependent on multiple, possibly correlated, risk factors. To thisend, a new class called derivatives_position is introduced to model an options/",
    "As for the preceding chapters on the DX derivatives analytics library, Glasserman (2004)is a comprehensive resource for Monte Carlo simulation in the context of financialengineering and applications. Hilpisch (2015) also provides Python-based implementations of the most important Monte Carlo algorithms:%E2%80%A2Glasserman, Paul (2004): Monte Carlo Methods in Financial Engineering. Springer,New York.%E2%80%A2Hilpisch, Yves (2015): Derivatives Analytics with Python. Wiley Finance, Chichester, England. http://derivatives-analytics-with-python.com.However, there is hardly any research available when it comes to the valuation of (complex) portfolios of derivatives in a consistent, nonredundant fashion by Monte Carlosimulation. A notable exception, at least from a conceptual point of view, is the briefarticle by Albanese, Gimonet, and White (2010a). A bit more detailed is the white paperby the same team of authors:%E2%80%A2Albanese, Claudio, Guillaume Gimonet, and Steve White (2010a): %E2%80%9CTowards aGlobal Valuation Model.%E2%80%9D Risk Magazine, May issue. http://bit.ly/risk_may_2010.",
    "This section collects step by step the necessary data to value the American put optionson the VSTOXX. First, let us import our libraries of choice when it comes to the gathering and management of data:In[1]:importnumpyasnpimportpandasaspd",
    "In Chapter 6, there is a regression example based on the VSTOXX and EURO STOXX50 indices. There, we also use the following public source for VSTOXX daily closingdata:In[2]:url='http://www.stoxx.com/download/historical_values/h_vstoxx.txt'vstoxx_index=pd.read_csv(url,index_col=0,header=2,parse_dates=True,dayfirst=True)",
    "The data set we use for the futures and options data is not publicly available in this form.It is a complete data set with daily prices for all instruments traded on the VSTOXXvolatility index provided by Eurex. The data set covers the complete first quarter of 2014:In[6]:vstoxx_futures=pd.read_excel('./source/vstoxx_march_2014.xlsx','vstoxx_futures')In[7]:vstoxx_futures.info()Out[7]: %3Cclass 'pandas.core.frame.DataFrame'%3E        Int64Index: 504 entries, 0 to 503",
    "At any time, there are eight futures traded on the VSTOXX. In comparison, there areof course many more options, such that we expect a much larger data set for the volatilityoptions. In fact, we have almost 47,000 option quotes for the first quarter of 2014:In[16]:vstoxx_options=pd.read_excel('./source/vstoxx_march_2014.xlsx','vstoxx_options')In[17]:vstoxx_options.info()Out[17]: %3Cclass 'pandas.core.frame.DataFrame'%3E         Int64Index: 46960 entries, 0 to 46959         Data columns (total 8 columns):         A_DATE                       46960 non-null datetime64[ns]         A_EXP_YEAR                   46960 non-null int64         A_EXP_MONTH                  46960 non-null int64         A_CALL_PUT_FLAG              46960 non-null object         A_EXERCISE_PRICE             46960 non-null int64         A_SETTLEMENT_PRICE_SCALED    46960 non-null int64",
    "The next important step is the calibration of the financial model used to value theVSTOXX options to available market data. For an in-depth discussion of this topic andexample code in Python see Hilpisch (2015), in particular Chapter 11.",
    "For the calibration of the square_root_diffusionmodel, the options selected beforehave to be modeled. This is the first time that the DXanalytics library comes into play%3Beverything else so far was %E2%80%9Cjust%E2%80%9D preparation for the following derivatives analytics tasks.We begin by importing the library:In[27]:fromdximport*The first task is then the definition of a market_environmentobject for the VSTOXXindex, in which we mainly store the previously collected and/or defined data:In[28]:me_vstoxx=market_environment('me_vstoxx',pricing_date)In[29]:me_vstoxx.add_constant('initial_value',initial_value)me_vstoxx.add_constant('final_date',maturity)me_vstoxx.add_constant('currency','EUR')In[30]:me_vstoxx.add_constant('frequency','B')me_vstoxx.add_constant('paths',10000)In[31]:csr=constant_short_rate('csr',0.01)# somewhat arbitrarily chosen hereIn[32]:me_vstoxx.add_curve('discount_curve',csr)The major goal of the calibration procedure is to derive optimal parameters for thesquare_root_diffusion simulation class, namely kappa, theta, and volatility.These are the, so to say, degrees of freedom that this class offers. All other parametersare in general dictated by the market or the task at hand.Although the three (optimal) parameters are to be numerically derived, we need toprovide some dummy values to instantiate the simulation class. For the volatilityparameter, we take the historical volatility given our data set:In[33]:# parameters to be calibrated laterme_vstoxx.add_constant('kappa',1.0)me_vstoxx.add_constant('theta',1.2*initial_value)vol_est=vstoxx_index['V2TX'].std() %5C*np.sqrt(len(vstoxx_index['V2TX'])/252.)me_vstoxx.add_constant('volatility',vol_est)In[34]:vol_estOut[34]: 1.0384283035169406Then we provide the market_environment object to the simulation class:In[35]:vstoxx_model=square_root_diffusion('vstoxx_model',me_vstoxx)",
    "Calibration of an option pricing model is, in general, a convex optimization problem.The most widely used function used for the calibration-i.e., the minimization-is themean-squared error(MSE) for the model option values given the market quotes of theoptions. Assume there are N relevant options, and also model and market quotes. Theproblem of calibrating a financial model to the market quotes based on the MSE is thengiven in Equation 19-1. There,  C n* and  C nmodare the market price and the model priceof the nth option, respectively. p is the parameter set provided as input to the optionpricing model.Equation 19-1. Model calibration based on mean-squared errorminp1N%E2%88%91n=1N C n*%E2%88%92 C nmodp2",
    "This chapter presents a larger, realistic use case for the application of the DXanalyticslibrary to the valuation of a portfolio of nontraded American options on the VSTOXXvolatility index. The chapter addresses three main tasks involved in any real-worldapplication:Data gatheringCurrent, correct market data builds the basis of any modeling and valuation effortin derivatives analytics%3B we need index data and futures data, as well as options datafor the VSTOXX.Model calibrationTo value, manage, and hedge nontraded options and derivatives in a market-consistent fashion, one needs to calibrate the model parameters to the relevantoption market quotes (relevant with regard to maturity and strikes). Our model ofchoice is the square-root diffusion, which is appropriate for modeling a volatilityindex%3B the calibration results are quite good although the model only offers threedegrees of freedom (kappa as the mean-reversion factor, thetaas the long-termvolatility, and volatility as the volatility of the volatility, or so-called %E2%80%9Cvol-vol%E2%80%9D).Portfolio valuationBased on the market data and the calibrated model, a portfolio with the Americanput options on the VSTOXX is modeled and major statistics (position values, Deltas,and Vegas) are generated.The realistic use case in this chapter shows the flexibility and the power of the DXlibrary%3Bit essentially allows us to address any analytical task with regard to derivatives. The veryapproach and architecture make the application largely comparable to the benchmarkcase of a Black-Scholes-Merton analytical formula for European options. Once the valuation objects are defined, you can use them similarly to an analytical formula-andthis despite the fact that underneath the surface, heavy numerical routines and algorithms are applied.",
    "One really helpful feature of Spyder as an integrated development environment is itsautomatic syntax and code checking, which checks Python code for compliance withthe PEP 8 recommendations for Pythonsyntax. But what is codified in %E2%80%9CPython Enhancement Proposal 8%E2%80%9D%3F Principally, there are some code formatting rules that shouldboth establish a common standard and allow for better readability of the code. In thatsense, this approach is not too dissimilar from a written or printed natural languagewhere certain syntax rules also apply.For example, consider the code in Example 1-1 of Chapter 1for the valuation of aEuropean call option via Monte Carlo simulation. First, have a look at the version ofthis code in Example A-1that does not conform to PEP 8. It is rather packed, becausethere are blank lines and spaces missing (sometimes there are also too many spaces orblank lines).Example A-1. A Python script that does not conform to PEP 8#   Monte Carlo valuation of European call option# in Black-Scholes-Merton model#  bsm_mcs_euro_syntax_false.pyimportnumpyasnp#Parameter ValuesS0=100.#initial index levelK=105.#strike priceT=1.0#time-to-maturity",
    "%2BAddition-Subtraction/Division*Multiplication%25Modulo==Is equal%3F!=Is not equal%3F%3CIs smaller%3F%3C=Is equal or smaller%3F%3EIs larger%3F%3E=Is equal or larger%3F",
    "The two main elements of Python documentation are:Inline documentationInline documentation can in principle be placed anywhere in the code%3B it is indicatedby the use of one or more leading hash characters (#). In general, there should beat least two spaces before a hash.Documentation stringsSuch strings are used to provide documentation for Pythonfunctions (methods)and classes, and are generally placed within their definition (at the beginning of theindented code).The code in Example A-2 contains multiple examples of inline documentation.Example A-4shows the same function definition as in Example A-3, but this time witha documentation string added.Example A-4. The Python function is_prime with documentation string## Function to check prime characteristic of integer# is_prime_with_doc.py#defis_prime(I):''' Function to test for prime characteristic of an integer.    Parameters    ==========",
    "As a final best practice, we want to consider unit testing. Among the different testingapproaches, unit testing can indeed be considered a best practice because it tests Pythoncode on a rather fundamental level-i.e., the single units. What it does not test, however,is the integration of the single units. Typically, such units are functions, classes, or",
    "test_f_calculationTests if the function generates correct resultstest_f_type_errorChecks if the function raises a type error when expectedtest_f_value_errorChecks if the function raises a value error when expectedtest_f_test_failsTests if the calculation test fails as expected (for illustration)From the command line/shell, you can run the following tests:%24 nosetests nose_test.py...F======================================================================FAIL: Test if function test fails. ---------------------------------------------------------------------- Traceback (most recent call last):",
    "The datetimemodule from the Pythonstandard library allows for the implementationof the most important date and time-related tasks.1 We start by importing the module:In[1]:importdatetimeasdtTwo different functions provide the exact current date and time:In[2]:dt.datetime.now()Out[2]: datetime.datetime(2014, 9, 14, 19, 22, 24, 366619)In[3]:to=dt.datetime.today()toOut[3]: datetime.datetime(2014, 9, 14, 19, 22, 24, 491234)The resulting object is a datetime object:In[4]:type(to)Out[4]: datetime.datetimeThe method weekday provides the number for the day of the week, given a datetimeobject:",
    "The pandaslibrary was specifically designed with time series data in mind. Therefore,the library provides classes that are able to efficiently handle date-time information, likethe DatetimeIndex class for time indices (cf. the documentation):In[66]:importpandasaspdDate-time information in pandas is generally stored as a Timestamp object:In[67]:ts=pd.Timestamp('2016-06-30')tsOut[67]: Timestamp('2016-06-30 00:00:00')Such objects are easily transformed into regular datetime objects with the to_datetimemethod:In[68]:d=ts.to_datetime()dOut[68]: datetime.datetime(2016, 6, 30, 0, 0)Similarly, a Timestampobject is straightforwardly constructed from a datetime object:In[69]:pd.Timestamp(d)Out[69]: Timestamp('2016-06-30 00:00:00')or from a NumPydatetime64 object:In[70]:pd.Timestamp(nd)Out[70]: Timestamp('2015-10-01 00:00:00')Another important class is the DatetimeIndex class, which is a collection of Timestampobjects with a number of powerful methods attached (cf. http://bit.ly/date_range_docand http://bit.ly/datetimeindex_doc). Such an object can be instantiated with thedate_range function, which is rather flexible and powerful for constructing time indices(see Chapter 6 for more details on this function):In[71]:dti=pd.date_range('2016/01/01',freq='M',periods=12)dti",
    "64-bit double precision standard, 83",
    "call optionsclass definition for European, 557%E2%80%93561definition of, 291candlestick plots, 128capital asset pricing model, 308capital market line, 332cash flow series, 391, 398cellsin DataNitro, 371in Excel spreadsheets, 363in IPython, 37characters, symbols for, 114classesaccessing attribute values, 382assigning new attribute values, 383attributes and, 382cash flow series example, 391defining, 382defining object attributes, 383for risk-neutral discounting, 460generic simulation class, 470generic valuation class, 489geometric Brownian motion, 473inheritance in, 382iteration over, 385jump diffusion, 478private attributes, 385readability and maintainability of, 384reusability and, 383simple short rate class example, 387square-root diffusion, 482to model derivatives portfolios, 516to model derivatives positions, 512valuation class for American exercise, 502valuation class for European exercise, 494coefficient of determination, 243color abbreviations, 114comma-separated value (CSV) filesgenerating Excel spreadsheets with, 359input-output operations with pandas, 188parameters of read_csv function, 161",
    "general market model, 457, 515General Purpose Graphical Processing Units(GPGPUs), 226generate_payoff method, 494geometric Brownian motion, 467, 473get_info method, 512global optimization, 250, 539graphical analysis, 67(see also matplotlib library)graphical user interfaces (GUIs)cash flow series with, 398libraries required, 393Microsoft Excel as, 358short rate class with, 394updating values, 396Greeks, estimation of, 492groupby operations, 150Gruenbichler and Longstaff model, 443Guassian quadrature, 256"
  ]
}
